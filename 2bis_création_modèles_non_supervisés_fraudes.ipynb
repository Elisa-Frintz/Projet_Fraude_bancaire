{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Fraude bancaire propre : Création des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "import fastparquet\n",
    "from dask_ml.preprocessing import DummyEncoder\n",
    "import pickle\n",
    "import dask_ml \n",
    "from dask import delayed\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import scikitplot as skplt\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "\n",
    "# Algorithmes\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import linear_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/jacky/Downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Importation du dataset\n",
    "Le pré-traitement du dataset a déjà été fait en amont. Nous importons donc directement le fichier au format dask à partir d'un format parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlagImpaye</th>\n",
       "      <th>Montant</th>\n",
       "      <th>CodeDecision</th>\n",
       "      <th>D2CB</th>\n",
       "      <th>ScoringFP1</th>\n",
       "      <th>ScoringFP2</th>\n",
       "      <th>ScoringFP3</th>\n",
       "      <th>TauxImpNb_RB</th>\n",
       "      <th>TauxImpNB_CPM</th>\n",
       "      <th>EcartNumCheq</th>\n",
       "      <th>NbrMagasin3J</th>\n",
       "      <th>DiffDateTr1</th>\n",
       "      <th>DiffDateTr2</th>\n",
       "      <th>DiffDateTr3</th>\n",
       "      <th>CA3TRetMtt</th>\n",
       "      <th>CA3TR</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.186668</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:32:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.844716</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.797685</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.61</td>\n",
       "      <td>8.61</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:43:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57.64</td>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.118280</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:47:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.056926</td>\n",
       "      <td>53.554234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:48:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26.90</td>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>8.586333</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>45.368313</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.997106</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.15</td>\n",
       "      <td>32.25</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>08:13:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlagImpaye  Montant  CodeDecision  D2CB  ScoringFP1  ScoringFP2  \\\n",
       "0           0    20.00             1   551    0.000000    0.000000   \n",
       "1           0    20.00             1   551    0.000000    0.000000   \n",
       "2           0    57.64             1   549    0.000000    0.000000   \n",
       "3           0    54.29             0   267    0.000000    0.000000   \n",
       "4           0    26.90             1   549    0.003769    8.586333   \n",
       "\n",
       "   ScoringFP3  TauxImpNb_RB  TauxImpNB_CPM  EcartNumCheq  NbrMagasin3J  \\\n",
       "0    0.000000     37.186668      52.076034             0             1   \n",
       "1    0.000000     48.844716      52.076034             1             2   \n",
       "2    0.000000     73.118280      52.076034             0             1   \n",
       "3    0.000000    110.056926      53.554234             0             1   \n",
       "4    0.001192     45.368313      52.076034             1             1   \n",
       "\n",
       "   DiffDateTr1  DiffDateTr2  DiffDateTr3  CA3TRetMtt  CA3TR        Date  \\\n",
       "0     4.000000          4.0          4.0       20.00   0.00  2017-02-01   \n",
       "1     1.797685          4.0          4.0       28.61   8.61  2017-02-01   \n",
       "2     4.000000          4.0          4.0       57.64   0.00  2017-02-01   \n",
       "3     4.000000          4.0          4.0       54.29   0.00  2017-02-01   \n",
       "4     1.997106          4.0          4.0       59.15  32.25  2017-02-01   \n",
       "\n",
       "      Heure  \n",
       "0  07:32:14  \n",
       "1  07:43:37  \n",
       "2  07:47:38  \n",
       "3  07:48:48  \n",
       "4  08:13:27  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_parquet('guillaumeb_parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Subdivision en apprentissage/test\n",
    " - dfTrain : du 2017-02-01 au 2017-08-31\n",
    " - dfTest : du 2017-09-01 au 2017-11-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canger le type de la variable \"CodeDecision\"\n",
    "df['CodeDecision'] = df['CodeDecision'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlagImpaye</th>\n",
       "      <th>Montant</th>\n",
       "      <th>CodeDecision</th>\n",
       "      <th>D2CB</th>\n",
       "      <th>ScoringFP1</th>\n",
       "      <th>ScoringFP2</th>\n",
       "      <th>ScoringFP3</th>\n",
       "      <th>TauxImpNb_RB</th>\n",
       "      <th>TauxImpNB_CPM</th>\n",
       "      <th>EcartNumCheq</th>\n",
       "      <th>NbrMagasin3J</th>\n",
       "      <th>DiffDateTr1</th>\n",
       "      <th>DiffDateTr2</th>\n",
       "      <th>DiffDateTr3</th>\n",
       "      <th>CA3TRetMtt</th>\n",
       "      <th>CA3TR</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.186668</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:32:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.844716</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.797685</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.61</td>\n",
       "      <td>8.61</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:43:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57.64</td>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.118280</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:47:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.056926</td>\n",
       "      <td>53.554234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07:48:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26.90</td>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>8.586333</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>45.368313</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.997106</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.15</td>\n",
       "      <td>32.25</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>08:13:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FlagImpaye  Montant CodeDecision  D2CB  ScoringFP1  ScoringFP2  ScoringFP3  \\\n",
       "0           0    20.00            1   551    0.000000    0.000000    0.000000   \n",
       "1           0    20.00            1   551    0.000000    0.000000    0.000000   \n",
       "2           0    57.64            1   549    0.000000    0.000000    0.000000   \n",
       "3           0    54.29            0   267    0.000000    0.000000    0.000000   \n",
       "4           0    26.90            1   549    0.003769    8.586333    0.001192   \n",
       "\n",
       "   TauxImpNb_RB  TauxImpNB_CPM  EcartNumCheq  NbrMagasin3J  DiffDateTr1  \\\n",
       "0     37.186668      52.076034             0             1     4.000000   \n",
       "1     48.844716      52.076034             1             2     1.797685   \n",
       "2     73.118280      52.076034             0             1     4.000000   \n",
       "3    110.056926      53.554234             0             1     4.000000   \n",
       "4     45.368313      52.076034             1             1     1.997106   \n",
       "\n",
       "   DiffDateTr2  DiffDateTr3  CA3TRetMtt  CA3TR        Date     Heure  \n",
       "0          4.0          4.0       20.00   0.00  2017-02-01  07:32:14  \n",
       "1          4.0          4.0       28.61   8.61  2017-02-01  07:43:37  \n",
       "2          4.0          4.0       57.64   0.00  2017-02-01  07:47:38  \n",
       "3          4.0          4.0       54.29   0.00  2017-02-01  07:48:48  \n",
       "4          4.0          4.0       59.15  32.25  2017-02-01  08:13:27  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = df.loc[df['Date'] <= '2017-08-31']\n",
    "dfTest = df.loc[df['Date'] >= '2017-09-01']\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Définir la variable cible (y) et les variables explicatives (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la variable cible \n",
    "yTrain = dfTrain[\"FlagImpaye\"]\n",
    "yTest = dfTest[\"FlagImpaye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les variables explicatives \n",
    "XTrain = dfTrain.drop([\"FlagImpaye\", \"Date\", \"Heure\", \"CA3TRetMtt\"], axis = \"columns\")\n",
    "XTest = dfTest.drop([\"FlagImpaye\", \"Date\", \"Heure\", \"CA3TRetMtt\"], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Recodage de la variable \"CodeDecision\" dans les varaibles explicatives\n",
    "- Rmq : La variable qualitative \"CodeDecision\" possède les modalités 0, 1, 2 et 3 dans dfTrain et les modalités 0, 2 et 3 dans dfTest. \n",
    "- Notre stratégie est la suivante : \n",
    "    1. Recodage de la variable \"CodeDecision\" dans les variables explicatives XTrain et XTest.\n",
    "    2. Comme la variable \"CodeDecision_1\" n'est présente que dans XTrain, elle devient inutile. Nous décidons donc de la supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans le dataframe d'apprentissage :\n",
      "0    2760391\n",
      "1    1121626\n",
      "2      15138\n",
      "3       2207\n",
      "Name: CodeDecision, dtype: int64\n",
      "-------------------------------------------------------\n",
      "Dans le dataframe de test :\n",
      "0    742395\n",
      "2      4424\n",
      "3       591\n",
      "Name: CodeDecision, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exposition du problème \n",
    "print(\"Dans le dataframe d'apprentissage :\")\n",
    "print(dfTrain['CodeDecision'].value_counts().compute())\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(\"Dans le dataframe de test :\")\n",
    "print(dfTest['CodeDecision'].value_counts().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Montant</th>\n",
       "      <th>D2CB</th>\n",
       "      <th>ScoringFP1</th>\n",
       "      <th>ScoringFP2</th>\n",
       "      <th>ScoringFP3</th>\n",
       "      <th>TauxImpNb_RB</th>\n",
       "      <th>TauxImpNB_CPM</th>\n",
       "      <th>EcartNumCheq</th>\n",
       "      <th>NbrMagasin3J</th>\n",
       "      <th>DiffDateTr1</th>\n",
       "      <th>DiffDateTr2</th>\n",
       "      <th>DiffDateTr3</th>\n",
       "      <th>CA3TR</th>\n",
       "      <th>CodeDecision_0</th>\n",
       "      <th>CodeDecision_2</th>\n",
       "      <th>CodeDecision_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.00</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.186668</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.00</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.844716</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.797685</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.64</td>\n",
       "      <td>549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.118280</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.29</td>\n",
       "      <td>267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.056926</td>\n",
       "      <td>53.554234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.90</td>\n",
       "      <td>549</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>8.586333</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>45.368313</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.997106</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Montant  D2CB  ScoringFP1  ScoringFP2  ScoringFP3  TauxImpNb_RB  \\\n",
       "0    20.00   551    0.000000    0.000000    0.000000     37.186668   \n",
       "1    20.00   551    0.000000    0.000000    0.000000     48.844716   \n",
       "2    57.64   549    0.000000    0.000000    0.000000     73.118280   \n",
       "3    54.29   267    0.000000    0.000000    0.000000    110.056926   \n",
       "4    26.90   549    0.003769    8.586333    0.001192     45.368313   \n",
       "\n",
       "   TauxImpNB_CPM  EcartNumCheq  NbrMagasin3J  DiffDateTr1  DiffDateTr2  \\\n",
       "0      52.076034             0             1     4.000000          4.0   \n",
       "1      52.076034             1             2     1.797685          4.0   \n",
       "2      52.076034             0             1     4.000000          4.0   \n",
       "3      53.554234             0             1     4.000000          4.0   \n",
       "4      52.076034             1             1     1.997106          4.0   \n",
       "\n",
       "   DiffDateTr3  CA3TR  CodeDecision_0  CodeDecision_2  CodeDecision_3  \n",
       "0          4.0   0.00               0               0               0  \n",
       "1          4.0   8.61               0               0               0  \n",
       "2          4.0   0.00               0               0               0  \n",
       "3          4.0   0.00               1               0               0  \n",
       "4          4.0  32.25               0               0               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Recodage de la variable \"CodeDecision\" dans les variables explicatives \n",
    "XTrain_ok = dd.get_dummies(XTrain.categorize(), prefix=['CodeDecision'])\n",
    "XTest_ok = dd.get_dummies(XTest.categorize(), prefix=['CodeDecision'])\n",
    "\n",
    "# 2) Supprimer la variable \"CodeDecision_1\" de dfTrain\n",
    "XTrain_ok = XTrain_ok.drop([\"CodeDecision_1\"], axis = \"columns\")\n",
    "XTrain_ok.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Centrer-réduire les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Montant</th>\n",
       "      <th>D2CB</th>\n",
       "      <th>ScoringFP1</th>\n",
       "      <th>ScoringFP2</th>\n",
       "      <th>ScoringFP3</th>\n",
       "      <th>TauxImpNb_RB</th>\n",
       "      <th>TauxImpNB_CPM</th>\n",
       "      <th>EcartNumCheq</th>\n",
       "      <th>NbrMagasin3J</th>\n",
       "      <th>DiffDateTr1</th>\n",
       "      <th>DiffDateTr2</th>\n",
       "      <th>DiffDateTr3</th>\n",
       "      <th>CA3TR</th>\n",
       "      <th>CodeDecision_0</th>\n",
       "      <th>CodeDecision_2</th>\n",
       "      <th>CodeDecision_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.420302</td>\n",
       "      <td>1.017656</td>\n",
       "      <td>-0.084590</td>\n",
       "      <td>-0.239505</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>-0.030212</td>\n",
       "      <td>0.818043</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>-0.194165</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>-0.301229</td>\n",
       "      <td>-0.451325</td>\n",
       "      <td>-0.202861</td>\n",
       "      <td>-1.556786</td>\n",
       "      <td>-0.062428</td>\n",
       "      <td>-0.023797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.420302</td>\n",
       "      <td>1.017656</td>\n",
       "      <td>-0.084590</td>\n",
       "      <td>-0.239505</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>0.162138</td>\n",
       "      <td>0.818043</td>\n",
       "      <td>-0.043812</td>\n",
       "      <td>4.975724</td>\n",
       "      <td>-1.945875</td>\n",
       "      <td>-0.301229</td>\n",
       "      <td>-0.451325</td>\n",
       "      <td>0.038808</td>\n",
       "      <td>-1.556786</td>\n",
       "      <td>-0.062428</td>\n",
       "      <td>-0.023797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.022127</td>\n",
       "      <td>1.008573</td>\n",
       "      <td>-0.084590</td>\n",
       "      <td>-0.239505</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>0.562636</td>\n",
       "      <td>0.818043</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>-0.194165</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>-0.301229</td>\n",
       "      <td>-0.451325</td>\n",
       "      <td>-0.202861</td>\n",
       "      <td>-1.556786</td>\n",
       "      <td>-0.062428</td>\n",
       "      <td>-0.023797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.057565</td>\n",
       "      <td>-0.272152</td>\n",
       "      <td>-0.084590</td>\n",
       "      <td>-0.239505</td>\n",
       "      <td>-0.275801</td>\n",
       "      <td>1.172099</td>\n",
       "      <td>0.906727</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>-0.194165</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>-0.301229</td>\n",
       "      <td>-0.451325</td>\n",
       "      <td>-0.202861</td>\n",
       "      <td>0.642349</td>\n",
       "      <td>-0.062428</td>\n",
       "      <td>-0.023797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.347310</td>\n",
       "      <td>1.008573</td>\n",
       "      <td>-0.084434</td>\n",
       "      <td>0.637044</td>\n",
       "      <td>-0.273204</td>\n",
       "      <td>0.104780</td>\n",
       "      <td>0.818043</td>\n",
       "      <td>-0.043812</td>\n",
       "      <td>-0.194165</td>\n",
       "      <td>-1.757421</td>\n",
       "      <td>-0.301229</td>\n",
       "      <td>-0.451325</td>\n",
       "      <td>0.702346</td>\n",
       "      <td>-1.556786</td>\n",
       "      <td>-0.062428</td>\n",
       "      <td>-0.023797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Montant      D2CB  ScoringFP1  ScoringFP2  ScoringFP3  TauxImpNb_RB  \\\n",
       "0 -0.420302  1.017656   -0.084590   -0.239505   -0.275801     -0.030212   \n",
       "1 -0.420302  1.017656   -0.084590   -0.239505   -0.275801      0.162138   \n",
       "2 -0.022127  1.008573   -0.084590   -0.239505   -0.275801      0.562636   \n",
       "3 -0.057565 -0.272152   -0.084590   -0.239505   -0.275801      1.172099   \n",
       "4 -0.347310  1.008573   -0.084434    0.637044   -0.273204      0.104780   \n",
       "\n",
       "   TauxImpNB_CPM  EcartNumCheq  NbrMagasin3J  DiffDateTr1  DiffDateTr2  \\\n",
       "0       0.818043     -0.043817     -0.194165     0.135329    -0.301229   \n",
       "1       0.818043     -0.043812      4.975724    -1.945875    -0.301229   \n",
       "2       0.818043     -0.043817     -0.194165     0.135329    -0.301229   \n",
       "3       0.906727     -0.043817     -0.194165     0.135329    -0.301229   \n",
       "4       0.818043     -0.043812     -0.194165    -1.757421    -0.301229   \n",
       "\n",
       "   DiffDateTr3     CA3TR  CodeDecision_0  CodeDecision_2  CodeDecision_3  \n",
       "0    -0.451325 -0.202861       -1.556786       -0.062428       -0.023797  \n",
       "1    -0.451325  0.038808       -1.556786       -0.062428       -0.023797  \n",
       "2    -0.451325 -0.202861       -1.556786       -0.062428       -0.023797  \n",
       "3    -0.451325 -0.202861        0.642349       -0.062428       -0.023797  \n",
       "4    -0.451325  0.702346       -1.556786       -0.062428       -0.023797  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciation de StandardScaler pour centrer réduire les données\n",
    "scaler = StandardScaler()\n",
    "\n",
    "XTrain_ok_scale = scaler.fit_transform(XTrain_ok)\n",
    "XTest_ok_scale = scaler.fit_transform(XTest_ok)\n",
    "XTrain_ok_scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcul_CA(Montant, yReel, yPred):\n",
    "    # Création de dfmerge\n",
    "    dfmerge = pd.concat([Montant, yReel], axis=1)\n",
    "    dfmerge[\"Ypred\"] = yPred\n",
    "    \n",
    "    # Création de la variable CA\n",
    "    dfmerge[\"CA\"] = dfmerge[\"Montant\"]\n",
    "    dfmerge.loc[((dfmerge[\"FlagImpaye\"] == -1) & (dfmerge[\"Ypred\"] == -1)), \"CA\"] = 0\n",
    "    dfmerge.loc[((dfmerge[\"FlagImpaye\"] == 1) & (dfmerge[\"Ypred\"] == -1)), \"CA\"] = 0.8 * dfmerge[\"Montant\"]\n",
    "    dfmerge.loc[((dfmerge[\"FlagImpaye\"] == -1) & (dfmerge[\"Ypred\"] == 1)), \"CA\"] = 1 - np.exp(1/dfmerge[\"Montant\"])\n",
    "    \n",
    "    # Calcul du CA_total\n",
    "    CA_total = dfmerge[\"CA\"].sum()\n",
    "    \n",
    "    return CA_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Création de la fonction de déploiement d'un modèle sur les données de test\"\"\"\n",
    "\n",
    "def deploiement(modele, XTest, yTest, scale):\n",
    "    XTest_ = XTest\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    if scale == True:\n",
    "        XTest = scaler.fit_transform(XTest)\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    # Importation du modèle \n",
    "    fichier = open(modele, \"rb\")\n",
    "    mdl = pickle.load(fichier)\n",
    "    fichier.close()\n",
    "    \n",
    "    # Affichage du modèle \n",
    "    print('Modèle :\\n', mdl)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    # Prédiction\n",
    "    Ypred = delayed(mdl.predict)(XTest).compute()\n",
    "    # Prédiction des scores\n",
    "    Yscore = delayed(mdl.predict_proba)(XTest).compute()\n",
    "    \n",
    "    \n",
    "    # Estimateurs, matrice de confusion et AUC\n",
    "    cm = delayed(confusion_matrix)(yTest, Ypred)\n",
    "    cr = delayed(classification_report)(yTest, Ypred)\n",
    "    auc = delayed(roc_auc_score)(yTest, Ypred)\n",
    "\n",
    "    print('Estimateurs :\\n', cr.compute())\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print('Matrice de confusion :\\n', cm.compute())\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print('Auc Score :\\n', auc.compute())\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "    # BONUS :  Calcul du chiffre d'affaire\n",
    "    CA_total = Calcul_CA(Montant = XTest_[\"Montant\"].compute(), yReel = yTest.compute(), yPred = Ypred)\n",
    "    print(\"Chiffre d'affaire = \" + str(round(CA_total, 2)) + \" euros\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "\n",
    "    # Courbe ROC\n",
    "    skplt.metrics.plot_roc(yTest, Yscore, classes_to_plot = 1, plot_micro = False, plot_macro = False)\n",
    "    # Courbe Précision-Rappel\n",
    "    skplt.metrics.plot_precision_recall(yTest, Yscore, classes_to_plot = 1, plot_micro = False)\n",
    "    return CA_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHMES NON-SUPERVISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------- Algorithme n°8 : SGD ONE CLASS SVM --------¶\n",
    "\n",
    "Nous allons tester le modèle en recherchant d'abord les meilleurs paramètres parmis une sélection.\n",
    "L'hyperparamètre 'nu' doit correspondre à la proportion d'outliers (ici, les fraudes) dans le jeu de données. Dans notre cas il est connu donc nous pouvons le fixer à 0.0065, mais nous allons également tester avec différentes valeurs pour mesurer la robustesse du modèle.\n",
    "\n",
    "Nous associons une approximation de kernel à l'algorithme avec Nystroem, pour avoir des résultats proches du One Class SVM classique qui n'est pas adapté aux grands jeux de données. Nous allons comparer les kernels suivants : \n",
    "\n",
    "- Radial : RBF\n",
    "- Polynomial de degré 5\n",
    "- Sigmoid\n",
    "\n",
    "Deux stratégies sont utilisées et comparées : \n",
    "\n",
    "- Outliers detection : le modèle est entraîné sur les deux classes. Il va apprendre à reconnaître ce qu'est un outlier pour le détecter dans l'échantillon test.\n",
    "\n",
    "- Novelty detection : approche semi-supervisée, le modèle ne sera entraîné que sur la classe majoritaire. Puis il réalisera les prédictions sur l'échantillon test contenant les deux classes. Les individus de la classe frauduleuse devraient être détectés comme \"différents\" par le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On recode en -1 et 1 pour les besoins de ces algorithmes qui affectent un score de -1 ou 1\n",
    "yTrain = yTrain.replace({1: -1, 0 : 1})\n",
    "yTest = yTest.replace({1: -1, 0 : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Montant</th>\n",
       "      <th>D2CB</th>\n",
       "      <th>ScoringFP1</th>\n",
       "      <th>ScoringFP2</th>\n",
       "      <th>ScoringFP3</th>\n",
       "      <th>TauxImpNb_RB</th>\n",
       "      <th>TauxImpNB_CPM</th>\n",
       "      <th>EcartNumCheq</th>\n",
       "      <th>NbrMagasin3J</th>\n",
       "      <th>DiffDateTr1</th>\n",
       "      <th>DiffDateTr2</th>\n",
       "      <th>DiffDateTr3</th>\n",
       "      <th>CA3TR</th>\n",
       "      <th>CodeDecision_0</th>\n",
       "      <th>CodeDecision_2</th>\n",
       "      <th>CodeDecision_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.00</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.186668</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.00</td>\n",
       "      <td>551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.844716</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.797685</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.64</td>\n",
       "      <td>549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.118280</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.29</td>\n",
       "      <td>267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.056926</td>\n",
       "      <td>53.554234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.90</td>\n",
       "      <td>549</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>8.586333</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>45.368313</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.997106</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Montant  D2CB  ScoringFP1  ScoringFP2  ScoringFP3  TauxImpNb_RB  \\\n",
       "0    20.00   551    0.000000    0.000000    0.000000     37.186668   \n",
       "1    20.00   551    0.000000    0.000000    0.000000     48.844716   \n",
       "2    57.64   549    0.000000    0.000000    0.000000     73.118280   \n",
       "3    54.29   267    0.000000    0.000000    0.000000    110.056926   \n",
       "4    26.90   549    0.003769    8.586333    0.001192     45.368313   \n",
       "\n",
       "   TauxImpNB_CPM  EcartNumCheq  NbrMagasin3J  DiffDateTr1  DiffDateTr2  \\\n",
       "0      52.076034             0             1     4.000000          4.0   \n",
       "1      52.076034             1             2     1.797685          4.0   \n",
       "2      52.076034             0             1     4.000000          4.0   \n",
       "3      53.554234             0             1     4.000000          4.0   \n",
       "4      52.076034             1             1     1.997106          4.0   \n",
       "\n",
       "   DiffDateTr3  CA3TR  CodeDecision_0  CodeDecision_2  CodeDecision_3  \n",
       "0          4.0   0.00               0               0               0  \n",
       "1          4.0   8.61               0               0               0  \n",
       "2          4.0   0.00               0               0               0  \n",
       "3          4.0   0.00               1               0               0  \n",
       "4          4.0  32.25               0               0               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train set avec la classe 0 uniquement\n",
    "df_0 = df[df['FlagImpaye'] == 0]\n",
    "XTrain_0 = df_0.loc[df['Date'] <= '2017-08-31']\n",
    "XTrain_0 = XTrain_0.drop([\"FlagImpaye\", \"Date\", \"Heure\", \"CA3TRetMtt\"], axis = \"columns\")\n",
    "\n",
    "# Recodage de la variable \"CodeDecision\" dans les variables explicatives \n",
    "XTrain_0 = dd.get_dummies(XTrain_0.categorize(), prefix=['CodeDecision'])\n",
    "\n",
    "# Supprimer la variable \"CodeDecision_1\" \n",
    "XTrain_0 = XTrain_0.drop([\"CodeDecision_1\"], axis = \"columns\")\n",
    "XTrain_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrage-Réduction des données ne comprenant que la classe non frauduleuse dans l'échantillon d'entraînement\n",
    "scaler_0 = StandardScaler()\n",
    "XTrain_0_scale = scaler_0.fit_transform(XTrain_0)\n",
    "XTest_0_scale = scaler_0.transform(XTest_ok)\n",
    "\n",
    "# Centrage-Réduction des données comprenant les deux classes dans l'échantillon d'entraînement\n",
    "scaler = StandardScaler()\n",
    "XTrain_ok_scale = scaler.fit_transform(XTrain_ok)\n",
    "XTest_ok_scale = scaler.transform(XTest_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers detection\n",
    "\n",
    "On entraîne le modèle sur les deux classes. \n",
    "Dans premier temps, on entraîne le modèle sans kernel. On fixe le paramètre nu à 0.0065.\n",
    "On utilise pour cet algorithme les données centrées et réduites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    13,   6560],\n",
       "       [  2895, 737942]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modèle\n",
    "osvm_linear = linear_model.SGDOneClassSVM(nu = 0.0065, max_iter = 2000, tol=1e-7, warm_start=False, random_state = 2, shuffle = True)\n",
    "  \n",
    "# Entraînement\n",
    "fit_osvm_linear = delayed(osvm_linear.fit)(XTrain_ok_scale)\n",
    "\n",
    "# Prédiction\n",
    "pred_osvm_linear = delayed(fit_osvm_linear.predict)(XTest_ok_scale)\n",
    "y_pred_OSVM_linear = pred_osvm_linear.compute()\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_osvm_linear = delayed(confusion_matrix)(yTest, y_pred_OSVM_linear).compute()\n",
    "print(cm_osvm_linear)\n",
    "\n",
    "# Métriques\n",
    "classif_osvm = delayed(classification_report)(yTest, y_pred_OSVM_linear).compute()\n",
    "print(classif_osvm)\n",
    "\n",
    "# AUC score\n",
    "print(round(roc_auc_score(yTest, y_pred_OSVM_linear), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ne sont pas satisfaisants. Ces données ne semblent pas être linéairement séparables. \n",
    "Nous allons donc utiliser des kernels.\n",
    "\n",
    "On teste dans un premier temps avec un kernel polynomial de degré 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3336,   3237],\n",
       "       [  1990, 738847]], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osvm_kernel = linear_model.SGDOneClassSVM(nu = 0.0065, shuffle=True, fit_intercept=True, random_state= 2, tol=1e-7, max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "\n",
    "transform = Nystroem(kernel = 'poly', gamma=0.0005, n_components = 25, random_state = 2, degree = 5, coef0 = None)\n",
    "pipeline_osvm = make_pipeline(transform, osvm_kernel)\n",
    "\n",
    "# Entraînement\n",
    "fit_osvm_kernel = delayed(pipeline_osvm.fit)(XTrain_ok_scale)\n",
    "\n",
    "# Prédiction\n",
    "pred_osvm_kernel = delayed(fit_osvm_kernel.predict)(XTest_ok_scale)\n",
    "y_pred_osvm_kernel = pred_osvm_kernel.compute()\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_osvm_kernel = delayed(confusion_matrix)(yTest, y_pred_osvm_kernel).compute()\n",
    "cm_osvm_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle, sans être excellent en rappel et précision, est bien plus performant que le précédent.\n",
    "L'expansion de base semble être une bonne piste sur laquelle nous allons poursuivre.\n",
    "\n",
    "Nous créons une fonction permettant de comparer différentes combinaisons de paramètres sans passer par une validation croisée inadaptée dans notre contexte.\n",
    "\n",
    "- Paramètre nu compris entre 0.0065 et 0.015\n",
    "- Paramètre gamma entre 0.0001 et 0.1\n",
    "- Paramètre n_components entre 5 et 25 : nombre de dimensions du nouvel espace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_OneClassSVM(X_train, X_test, yTest, kernel, degree = None):    \n",
    "    \n",
    "    # Hyperparamètres\n",
    "    nu = [0.0065, 0.08, 0.01, 0.015]\n",
    "    gamma = [0.1, 0.05, 0.01, 0.005, 0.0005, 0.0001]\n",
    "    n_components = [5, 15, 25]\n",
    "    \n",
    "    # Instanciation pour le stockage des résultats de performance\n",
    "    results_osvm = []\n",
    "\n",
    "    # Tests de toutes les combinaisons\n",
    "    for i in nu:\n",
    "        for j in gamma:\n",
    "            for l in n_components:\n",
    "                # Instanciation du modèle avec la kernel approximation     \n",
    "                osvm = linear_model.SGDOneClassSVM(nu=i, shuffle=True, fit_intercept=True, random_state=2, tol=1e-7, max_iter = 2000)\n",
    "                transform = Nystroem(kernel = kernel, gamma=j, n_components = l, random_state=2, degree = degree, n_jobs = -2)\n",
    "\n",
    "                # Pipeline\n",
    "                pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "                # Entraînement\n",
    "                fit_osvm = delayed(pipeline_osvm.fit)(X_train)\n",
    "\n",
    "                # Prédiction\n",
    "                pred_osvm = delayed(fit_osvm.predict)(X_test)\n",
    "                y_pred_osvm = pred_osvm.compute()\n",
    "                \n",
    "                # Matrice de confusion\n",
    "                cm_osvm = delayed(confusion_matrix)(yTest, y_pred_osvm).compute()\n",
    "\n",
    "                # Stockage des résultats de performance\n",
    "                results_osvm.append({'Vrais positifs' : cm_osvm[0][0],\n",
    "                                     'Faux négatifs' : cm_osvm[0][1],\n",
    "                                     'Faux positifs' : cm_osvm[1][0],\n",
    "                                     'Vrais negatifs' : cm_osvm[1][1],\n",
    "                                     'Accuracy' : delayed(accuracy_score)(yTest, y_pred_osvm).compute(),\n",
    "                                     'Precision classe 1' : delayed(precision_score)(yTest, y_pred_osvm, pos_label = -1, average= 'binary', labels=np.unique(y_pred_osvm)).compute(),\n",
    "                                     'Precision classe 0' : delayed(precision_score)(yTest, y_pred_osvm, pos_label = 1, average= 'binary', labels=np.unique(y_pred_osvm)).compute(),\n",
    "                                     'Rappel classe 1' : delayed(recall_score)(yTest, y_pred_osvm, pos_label = -1, average= 'binary').compute(),\n",
    "                                     'Rappel classe 0' : delayed(recall_score)(yTest, y_pred_osvm, pos_label = 1, average= 'binary').compute(),\n",
    "                                     'f1-score classe 1' : delayed(f1_score)(yTest, y_pred_osvm, pos_label = -1, average= 'binary').compute(),\n",
    "                                     'f1-score classe 0' : delayed(f1_score)(yTest, y_pred_osvm, pos_label = 1, average= 'binary').compute(),\n",
    "                                     'roc_auc_score' : round(roc_auc_score(yTest, y_pred_osvm), 4),\n",
    "                                     'nu' : i,\n",
    "                                     'gamma' : j,\n",
    "                                     'n_components' : l\n",
    "                                   })\n",
    "\n",
    "    # Conversion en DataFrame\n",
    "    results_osvm = pd.DataFrame(results_osvm)\n",
    "    results_osvm = results_osvm.sort_values(by='f1-score classe 1', ascending=False)\n",
    "    return results_osvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de déploiement pour One Class SVM et Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Création de la fonction de déploiement d'un modèle sur les données de test\"\"\"\n",
    "\n",
    "def deploiement_unsupervised(modele, XTest, yTest, scale, X_ca):\n",
    "    XTest_ = XTest\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    if scale == True:\n",
    "        XTest = scaler.fit_transform(XTest)\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    # Importation du modèle \n",
    "    fichier = open(modele, \"rb\")\n",
    "    mdl = pickle.load(fichier)\n",
    "    fichier.close()\n",
    "    \n",
    "    # Affichage du modèle \n",
    "    print('Modèle :\\n', mdl)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    # Prédiction\n",
    "    Ypred = delayed(mdl.predict)(XTest).compute()\n",
    "    #Ypred = [1 if x == -1 else 0 for x in Ypred]\n",
    "    # Prédiction des scores\n",
    "    \n",
    "    # Estimateurs, matrice de confusion et AUC\n",
    "    cm = delayed(confusion_matrix)(yTest, Ypred)\n",
    "    cr = delayed(classification_report)(yTest, Ypred)\n",
    "    auc = delayed(roc_auc_score)(yTest, Ypred)\n",
    "\n",
    "    print('Estimateurs :\\n', cr.compute())\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print('Matrice de confusion :\\n', cm.compute())\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print('Auc Score :\\n', auc.compute())\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "    # BONUS :  Calcul du chiffre d'affaire\n",
    "    CA_total = Calcul_CA(Montant = X_ca[\"Montant\"].compute(), yReel = yTest.compute(), yPred = Ypred)\n",
    "    print(\"Chiffre d'affaire = \" + str(round(CA_total, 2)) + \" euros\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "    \n",
    "    return CA_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Radial\n",
    "\n",
    "On teste les paramètres avec un kernel radial : RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50min 8s\n"
     ]
    }
   ],
   "source": [
    "%time Results_rbf = Model_OneClassSVM(X_train = XTrain_ok_scale, X_test = XTest_ok_scale, yTest = yTest, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>nu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4234</td>\n",
       "      <td>2339</td>\n",
       "      <td>2785</td>\n",
       "      <td>738052</td>\n",
       "      <td>0.993144</td>\n",
       "      <td>0.603220</td>\n",
       "      <td>0.996841</td>\n",
       "      <td>0.644150</td>\n",
       "      <td>0.996241</td>\n",
       "      <td>0.623014</td>\n",
       "      <td>0.996541</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4096</td>\n",
       "      <td>2477</td>\n",
       "      <td>2700</td>\n",
       "      <td>738137</td>\n",
       "      <td>0.993073</td>\n",
       "      <td>0.602707</td>\n",
       "      <td>0.996655</td>\n",
       "      <td>0.623155</td>\n",
       "      <td>0.996355</td>\n",
       "      <td>0.612761</td>\n",
       "      <td>0.996505</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4011</td>\n",
       "      <td>2562</td>\n",
       "      <td>2757</td>\n",
       "      <td>738080</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.592642</td>\n",
       "      <td>0.996541</td>\n",
       "      <td>0.610224</td>\n",
       "      <td>0.996279</td>\n",
       "      <td>0.601304</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4564</td>\n",
       "      <td>2009</td>\n",
       "      <td>4105</td>\n",
       "      <td>736732</td>\n",
       "      <td>0.991820</td>\n",
       "      <td>0.526474</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.694356</td>\n",
       "      <td>0.994459</td>\n",
       "      <td>0.598872</td>\n",
       "      <td>0.995868</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3977</td>\n",
       "      <td>2596</td>\n",
       "      <td>2826</td>\n",
       "      <td>738011</td>\n",
       "      <td>0.992746</td>\n",
       "      <td>0.584595</td>\n",
       "      <td>0.996495</td>\n",
       "      <td>0.605051</td>\n",
       "      <td>0.996185</td>\n",
       "      <td>0.594647</td>\n",
       "      <td>0.996340</td>\n",
       "      <td>0.8006</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3915</td>\n",
       "      <td>2658</td>\n",
       "      <td>3050</td>\n",
       "      <td>737787</td>\n",
       "      <td>0.992363</td>\n",
       "      <td>0.562096</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.595618</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>0.578372</td>\n",
       "      <td>0.996147</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4587</td>\n",
       "      <td>1986</td>\n",
       "      <td>5330</td>\n",
       "      <td>735507</td>\n",
       "      <td>0.990212</td>\n",
       "      <td>0.462539</td>\n",
       "      <td>0.997307</td>\n",
       "      <td>0.697855</td>\n",
       "      <td>0.992805</td>\n",
       "      <td>0.556337</td>\n",
       "      <td>0.995051</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4588</td>\n",
       "      <td>1985</td>\n",
       "      <td>5356</td>\n",
       "      <td>735481</td>\n",
       "      <td>0.990178</td>\n",
       "      <td>0.461384</td>\n",
       "      <td>0.997308</td>\n",
       "      <td>0.698007</td>\n",
       "      <td>0.992770</td>\n",
       "      <td>0.555549</td>\n",
       "      <td>0.995034</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3647</td>\n",
       "      <td>2926</td>\n",
       "      <td>3006</td>\n",
       "      <td>737831</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.548174</td>\n",
       "      <td>0.996050</td>\n",
       "      <td>0.554846</td>\n",
       "      <td>0.995942</td>\n",
       "      <td>0.551489</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4598</td>\n",
       "      <td>1975</td>\n",
       "      <td>5585</td>\n",
       "      <td>735252</td>\n",
       "      <td>0.989885</td>\n",
       "      <td>0.451537</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.699528</td>\n",
       "      <td>0.992461</td>\n",
       "      <td>0.548818</td>\n",
       "      <td>0.994885</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "16            4234           2339           2785          738052  0.993144   \n",
       "17            4096           2477           2700          738137  0.993073   \n",
       "14            4011           2562           2757          738080  0.992883   \n",
       "3             4564           2009           4105          736732  0.991820   \n",
       "13            3977           2596           2826          738011  0.992746   \n",
       "8             3915           2658           3050          737787  0.992363   \n",
       "4             4587           1986           5330          735507  0.990212   \n",
       "5             4588           1985           5356          735481  0.990178   \n",
       "11            3647           2926           3006          737831  0.992063   \n",
       "52            4598           1975           5585          735252  0.989885   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "16            0.603220            0.996841         0.644150         0.996241   \n",
       "17            0.602707            0.996655         0.623155         0.996355   \n",
       "14            0.592642            0.996541         0.610224         0.996279   \n",
       "3             0.526474            0.997281         0.694356         0.994459   \n",
       "13            0.584595            0.996495         0.605051         0.996185   \n",
       "8             0.562096            0.996410         0.595618         0.995883   \n",
       "4             0.462539            0.997307         0.697855         0.992805   \n",
       "5             0.461384            0.997308         0.698007         0.992770   \n",
       "11            0.548174            0.996050         0.554846         0.995942   \n",
       "52            0.451537            0.997321         0.699528         0.992461   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score      nu   gamma  \\\n",
       "16           0.623014           0.996541         0.8202  0.0065  0.0001   \n",
       "17           0.612761           0.996505         0.8098  0.0065  0.0001   \n",
       "14           0.601304           0.996410         0.8033  0.0065  0.0005   \n",
       "3            0.598872           0.995868         0.8444  0.0065  0.0500   \n",
       "13           0.594647           0.996340         0.8006  0.0065  0.0005   \n",
       "8            0.578372           0.996147         0.7958  0.0065  0.0100   \n",
       "4            0.556337           0.995051         0.8453  0.0065  0.0500   \n",
       "5            0.555549           0.995034         0.8454  0.0065  0.0500   \n",
       "11           0.551489           0.995996         0.7754  0.0065  0.0050   \n",
       "52           0.548818           0.994885         0.8460  0.0100  0.0001   \n",
       "\n",
       "   n_components  \n",
       "16  [5, 15, 25]  \n",
       "17  [5, 15, 25]  \n",
       "14  [5, 15, 25]  \n",
       "3   [5, 15, 25]  \n",
       "13  [5, 15, 25]  \n",
       "8   [5, 15, 25]  \n",
       "4   [5, 15, 25]  \n",
       "5   [5, 15, 25]  \n",
       "11  [5, 15, 25]  \n",
       "52  [5, 15, 25]  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_rbf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle à kernel radial\n",
    "\n",
    "Nous prenons les paramètres du modèle ayant le meilleur f1-score sur la classe frauduleuse. On voit cependant que les meilleurs résultats sont assez proches. Le paramètres nu = 0.0065 et gamma = 0.0001 donnent les meilleurs résultats.\n",
    "Les performances sont tout de même assez médiocres avec une précision et un rappel de 60% et 62% respectivement pour la classe frauduleuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle ayant les meilleures performances\n",
    "osvm = linear_model.SGDOneClassSVM(nu=0.0065, \n",
    "                                   fit_intercept=True, \n",
    "                                   random_state=2, \n",
    "                                   tol=1e-7, \n",
    "                                   max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "transform = Nystroem(kernel = 'rbf', \n",
    "                     gamma= 0.0001, \n",
    "                     n_components = 15, \n",
    "                     random_state=2, \n",
    "                     degree = None, \n",
    "                     n_jobs = -2)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_osvm = delayed(pipeline_osvm.fit)(XTrain_ok_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.0001, n_components=15, n_jobs=-2,\n",
      "                          random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.0065, random_state=2,\n",
      "                                tol=1e-07))])\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_osvm.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele8_rbf.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.0001, n_components=15, n_jobs=-2,\n",
      "                          random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.0065, random_state=2,\n",
      "                                tol=1e-07))])\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.64      0.62      6573\n",
      "           1       1.00      1.00      1.00    740837\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.80      0.82      0.81    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4234   2339]\n",
      " [  2785 738052]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8201955251989856\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45521104.44 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep8 = deploiement_unsupervised(modele = \"modele8_rbf.sav\", XTest = XTest_ok_scale, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Polynomial de degré 5\n",
    "\n",
    "Testons maintenant avec le kernel polynomial de degré 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 48min 58s\n"
     ]
    }
   ],
   "source": [
    "%time Results_polynomial = Model_OneClassSVM(X_train = XTrain_ok_scale, X_test = XTest_ok_scale, yTest = yTest, kernel = 'poly', degree = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>nu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4291</td>\n",
       "      <td>2282</td>\n",
       "      <td>1494</td>\n",
       "      <td>739343</td>\n",
       "      <td>0.994948</td>\n",
       "      <td>0.741746</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>0.652822</td>\n",
       "      <td>0.997983</td>\n",
       "      <td>0.694449</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4283</td>\n",
       "      <td>2290</td>\n",
       "      <td>2435</td>\n",
       "      <td>738402</td>\n",
       "      <td>0.993678</td>\n",
       "      <td>0.637541</td>\n",
       "      <td>0.996908</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>0.644496</td>\n",
       "      <td>0.996811</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4287</td>\n",
       "      <td>2286</td>\n",
       "      <td>2859</td>\n",
       "      <td>737978</td>\n",
       "      <td>0.993116</td>\n",
       "      <td>0.599916</td>\n",
       "      <td>0.996912</td>\n",
       "      <td>0.652214</td>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.624973</td>\n",
       "      <td>0.996526</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3540</td>\n",
       "      <td>3033</td>\n",
       "      <td>1276</td>\n",
       "      <td>739561</td>\n",
       "      <td>0.994235</td>\n",
       "      <td>0.735050</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>0.538567</td>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.621652</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>0.7684</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3837</td>\n",
       "      <td>2736</td>\n",
       "      <td>2337</td>\n",
       "      <td>738500</td>\n",
       "      <td>0.993213</td>\n",
       "      <td>0.621477</td>\n",
       "      <td>0.996309</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.602024</td>\n",
       "      <td>0.996577</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3818</td>\n",
       "      <td>2755</td>\n",
       "      <td>2429</td>\n",
       "      <td>738408</td>\n",
       "      <td>0.993064</td>\n",
       "      <td>0.611173</td>\n",
       "      <td>0.996283</td>\n",
       "      <td>0.580861</td>\n",
       "      <td>0.996721</td>\n",
       "      <td>0.595632</td>\n",
       "      <td>0.996502</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3336</td>\n",
       "      <td>3237</td>\n",
       "      <td>1990</td>\n",
       "      <td>738847</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.626361</td>\n",
       "      <td>0.995638</td>\n",
       "      <td>0.507531</td>\n",
       "      <td>0.997314</td>\n",
       "      <td>0.560719</td>\n",
       "      <td>0.996475</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2927</td>\n",
       "      <td>3646</td>\n",
       "      <td>1448</td>\n",
       "      <td>739389</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.669029</td>\n",
       "      <td>0.995093</td>\n",
       "      <td>0.445307</td>\n",
       "      <td>0.998045</td>\n",
       "      <td>0.534710</td>\n",
       "      <td>0.996567</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3303</td>\n",
       "      <td>3270</td>\n",
       "      <td>3590</td>\n",
       "      <td>737247</td>\n",
       "      <td>0.990822</td>\n",
       "      <td>0.479182</td>\n",
       "      <td>0.995584</td>\n",
       "      <td>0.502510</td>\n",
       "      <td>0.995154</td>\n",
       "      <td>0.490569</td>\n",
       "      <td>0.995369</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3229</td>\n",
       "      <td>3344</td>\n",
       "      <td>3681</td>\n",
       "      <td>737156</td>\n",
       "      <td>0.990601</td>\n",
       "      <td>0.467294</td>\n",
       "      <td>0.995484</td>\n",
       "      <td>0.491252</td>\n",
       "      <td>0.995031</td>\n",
       "      <td>0.478974</td>\n",
       "      <td>0.995258</td>\n",
       "      <td>0.7431</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "71            4291           2282           1494          739343  0.994948   \n",
       "70            4283           2290           2435          738402  0.993678   \n",
       "67            4287           2286           2859          737978  0.993116   \n",
       "17            3540           3033           1276          739561  0.994235   \n",
       "49            3837           2736           2337          738500  0.993213   \n",
       "52            3818           2755           2429          738408  0.993064   \n",
       "14            3336           3237           1990          738847  0.993007   \n",
       "16            2927           3646           1448          739389  0.993184   \n",
       "7             3303           3270           3590          737247  0.990822   \n",
       "11            3229           3344           3681          737156  0.990601   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "71            0.741746            0.996923         0.652822         0.997983   \n",
       "70            0.637541            0.996908         0.651605         0.996713   \n",
       "67            0.599916            0.996912         0.652214         0.996141   \n",
       "17            0.735050            0.995916         0.538567         0.998278   \n",
       "49            0.621477            0.996309         0.583752         0.996845   \n",
       "52            0.611173            0.996283         0.580861         0.996721   \n",
       "14            0.626361            0.995638         0.507531         0.997314   \n",
       "16            0.669029            0.995093         0.445307         0.998045   \n",
       "7             0.479182            0.995584         0.502510         0.995154   \n",
       "11            0.467294            0.995484         0.491252         0.995031   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score      nu   gamma  \\\n",
       "71           0.694449           0.997453         0.8254  0.0150  0.0001   \n",
       "70           0.644496           0.996811         0.8242  0.0150  0.0001   \n",
       "67           0.624973           0.996526         0.8242  0.0150  0.0005   \n",
       "17           0.621652           0.997095         0.7684  0.0065  0.0001   \n",
       "49           0.602024           0.996577         0.7903  0.0100  0.0005   \n",
       "52           0.595632           0.996502         0.7888  0.0100  0.0001   \n",
       "14           0.560719           0.996475         0.7524  0.0065  0.0005   \n",
       "16           0.534710           0.996567         0.7217  0.0065  0.0001   \n",
       "7            0.490569           0.995369         0.7488  0.0065  0.0100   \n",
       "11           0.478974           0.995258         0.7431  0.0065  0.0050   \n",
       "\n",
       "   n_components  \n",
       "71  [5, 15, 25]  \n",
       "70  [5, 15, 25]  \n",
       "67  [5, 15, 25]  \n",
       "17  [5, 15, 25]  \n",
       "49  [5, 15, 25]  \n",
       "52  [5, 15, 25]  \n",
       "14  [5, 15, 25]  \n",
       "16  [5, 15, 25]  \n",
       "7   [5, 15, 25]  \n",
       "11  [5, 15, 25]  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_polynomial.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle à kernel polynomial\n",
    "\n",
    "Les meilleurs modèles sont bien plus performants que les précédents en kernel radial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle ayant les meilleures performances\n",
    "osvm = linear_model.SGDOneClassSVM(nu=0.015, \n",
    "                                   fit_intercept=True, \n",
    "                                   random_state=2, \n",
    "                                   tol=1e-7, \n",
    "                                   max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "transform = Nystroem(kernel = 'poly', \n",
    "                     gamma= 0.0001, \n",
    "                     n_components = 25, \n",
    "                     random_state=2, \n",
    "                     degree = 5, \n",
    "                     n_jobs = -2)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_osvm = delayed(pipeline_osvm.fit)(XTrain_ok_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(degree=5, gamma=0.0001, kernel='poly',\n",
      "                          n_components=25, n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.015, random_state=2,\n",
      "                                tol=1e-07))])\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_osvm.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele8_poly.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(degree=5, gamma=0.0001, kernel='poly',\n",
      "                          n_components=25, n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.015, random_state=2,\n",
      "                                tol=1e-07))])\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.65      0.69      6573\n",
      "           1       1.00      1.00      1.00    740837\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.87      0.83      0.85    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4291   2282]\n",
      " [  1494 739343]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8254027566434036\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45863615.79 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep9 = deploiement_unsupervised(modele = \"modele8_poly.sav\", XTest = XTest_ok_scale, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time Results_sigmoid = Model_OneClassSVM(X_train = XTrain_ok_scale, X_test = XTest_ok_scale, yTest = yTest, kernel = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>nu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4288</td>\n",
       "      <td>2285</td>\n",
       "      <td>1403</td>\n",
       "      <td>739434</td>\n",
       "      <td>0.995066</td>\n",
       "      <td>0.753470</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>0.652366</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>0.699282</td>\n",
       "      <td>0.997512</td>\n",
       "      <td>0.8252</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4280</td>\n",
       "      <td>2293</td>\n",
       "      <td>1612</td>\n",
       "      <td>739225</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.726409</td>\n",
       "      <td>0.996908</td>\n",
       "      <td>0.651149</td>\n",
       "      <td>0.997824</td>\n",
       "      <td>0.686723</td>\n",
       "      <td>0.997366</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4128</td>\n",
       "      <td>2445</td>\n",
       "      <td>1324</td>\n",
       "      <td>739513</td>\n",
       "      <td>0.994957</td>\n",
       "      <td>0.757153</td>\n",
       "      <td>0.996705</td>\n",
       "      <td>0.628024</td>\n",
       "      <td>0.998213</td>\n",
       "      <td>0.686570</td>\n",
       "      <td>0.997458</td>\n",
       "      <td>0.8131</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4012</td>\n",
       "      <td>2561</td>\n",
       "      <td>1418</td>\n",
       "      <td>739419</td>\n",
       "      <td>0.994676</td>\n",
       "      <td>0.738858</td>\n",
       "      <td>0.996548</td>\n",
       "      <td>0.610376</td>\n",
       "      <td>0.998086</td>\n",
       "      <td>0.668500</td>\n",
       "      <td>0.997317</td>\n",
       "      <td>0.8042</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4295</td>\n",
       "      <td>2278</td>\n",
       "      <td>2048</td>\n",
       "      <td>738789</td>\n",
       "      <td>0.994212</td>\n",
       "      <td>0.677124</td>\n",
       "      <td>0.996926</td>\n",
       "      <td>0.653431</td>\n",
       "      <td>0.997236</td>\n",
       "      <td>0.665067</td>\n",
       "      <td>0.997081</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3833</td>\n",
       "      <td>2740</td>\n",
       "      <td>1201</td>\n",
       "      <td>739636</td>\n",
       "      <td>0.994727</td>\n",
       "      <td>0.761422</td>\n",
       "      <td>0.996309</td>\n",
       "      <td>0.583143</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.660464</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4491</td>\n",
       "      <td>2082</td>\n",
       "      <td>2555</td>\n",
       "      <td>738282</td>\n",
       "      <td>0.993796</td>\n",
       "      <td>0.637383</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.683250</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.659520</td>\n",
       "      <td>0.996869</td>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3961</td>\n",
       "      <td>2612</td>\n",
       "      <td>1760</td>\n",
       "      <td>739077</td>\n",
       "      <td>0.994150</td>\n",
       "      <td>0.692361</td>\n",
       "      <td>0.996478</td>\n",
       "      <td>0.602617</td>\n",
       "      <td>0.997624</td>\n",
       "      <td>0.644379</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3670</td>\n",
       "      <td>2903</td>\n",
       "      <td>1406</td>\n",
       "      <td>739431</td>\n",
       "      <td>0.994235</td>\n",
       "      <td>0.723010</td>\n",
       "      <td>0.996089</td>\n",
       "      <td>0.558345</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.630097</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3772</td>\n",
       "      <td>2801</td>\n",
       "      <td>1782</td>\n",
       "      <td>739055</td>\n",
       "      <td>0.993868</td>\n",
       "      <td>0.679150</td>\n",
       "      <td>0.996224</td>\n",
       "      <td>0.573863</td>\n",
       "      <td>0.997595</td>\n",
       "      <td>0.622083</td>\n",
       "      <td>0.996909</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>[5, 15, 25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "71            4288           2285           1403          739434  0.995066   \n",
       "68            4280           2293           1612          739225  0.994775   \n",
       "53            4128           2445           1324          739513  0.994957   \n",
       "50            4012           2561           1418          739419  0.994676   \n",
       "70            4295           2278           2048          738789  0.994212   \n",
       "17            3833           2740           1201          739636  0.994727   \n",
       "35            4491           2082           2555          738282  0.993796   \n",
       "52            3961           2612           1760          739077  0.994150   \n",
       "16            3670           2903           1406          739431  0.994235   \n",
       "49            3772           2801           1782          739055  0.993868   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "71            0.753470            0.996919         0.652366         0.998106   \n",
       "68            0.726409            0.996908         0.651149         0.997824   \n",
       "53            0.757153            0.996705         0.628024         0.998213   \n",
       "50            0.738858            0.996548         0.610376         0.998086   \n",
       "70            0.677124            0.996926         0.653431         0.997236   \n",
       "17            0.761422            0.996309         0.583143         0.998379   \n",
       "35            0.637383            0.997188         0.683250         0.996551   \n",
       "52            0.692361            0.996478         0.602617         0.997624   \n",
       "16            0.723010            0.996089         0.558345         0.998102   \n",
       "49            0.679150            0.996224         0.573863         0.997595   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score      nu   gamma  \\\n",
       "71           0.699282           0.997512         0.8252  0.0150  0.0001   \n",
       "68           0.686723           0.997366         0.8245  0.0150  0.0005   \n",
       "53           0.686570           0.997458         0.8131  0.0100  0.0001   \n",
       "50           0.668500           0.997317         0.8042  0.0100  0.0005   \n",
       "70           0.665067           0.997081         0.8253  0.0150  0.0001   \n",
       "17           0.660464           0.997343         0.7908  0.0065  0.0001   \n",
       "35           0.659520           0.996869         0.8399  0.0800  0.0001   \n",
       "52           0.644379           0.997051         0.8001  0.0100  0.0001   \n",
       "16           0.630097           0.997095         0.7782  0.0065  0.0001   \n",
       "49           0.622083           0.996909         0.7857  0.0100  0.0005   \n",
       "\n",
       "   n_components  \n",
       "71  [5, 15, 25]  \n",
       "68  [5, 15, 25]  \n",
       "53  [5, 15, 25]  \n",
       "50  [5, 15, 25]  \n",
       "70  [5, 15, 25]  \n",
       "17  [5, 15, 25]  \n",
       "35  [5, 15, 25]  \n",
       "52  [5, 15, 25]  \n",
       "16  [5, 15, 25]  \n",
       "49  [5, 15, 25]  "
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_sigmoid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle à kernel sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle ayant les meilleures performances\n",
    "osvm = linear_model.SGDOneClassSVM(nu=0.015, \n",
    "                                   fit_intercept=True, \n",
    "                                   random_state=2, \n",
    "                                   tol=1e-7, \n",
    "                                   max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "transform = Nystroem(kernel = 'sigmoid', \n",
    "                     gamma= 0.0001, \n",
    "                     n_components = 25, \n",
    "                     random_state=2, \n",
    "                     degree = None, \n",
    "                     n_jobs = -2)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_osvm = delayed(pipeline_osvm.fit)(XTrain_ok_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.0001, kernel='sigmoid', n_components=25,\n",
      "                          n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.015, random_state=2,\n",
      "                                tol=1e-07))])\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_osvm.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele8_sigmoid.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.0001, kernel='sigmoid', n_components=25,\n",
      "                          n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.015, random_state=2,\n",
      "                                tol=1e-07))])\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.65      0.70      6573\n",
      "           1       1.00      1.00      1.00    740837\n",
      "\n",
      "    accuracy                           1.00    747410\n",
      "   macro avg       0.88      0.83      0.85    747410\n",
      "weighted avg       0.99      1.00      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4288   2285]\n",
      " [  1403 739434]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8252359673637683\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45864667.39 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep10 = deploiement_unsupervised(modele = \"modele8_sigmoid.sav\", XTest = XTest_ok_scale, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results_rbf.to_csv(\"C:/Users/jacky/OneDrive/Bureau/OSVM_RBF.csv\")\n",
    "Results_polynomial.to_csv(\"C:/Users/jacky/OneDrive/Bureau/OSVM_POLY.csv\")\n",
    "Results_sigmoid.to_csv(\"C:/Users/jacky/OneDrive/Bureau/OSVM_SIGMOID.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty detection\n",
    "\n",
    "On réitère le même protocole, mais cette fois-ci, on entraîne le modèle sur les données sur la classe non frauduleuse uniquement. On s'attend à ce que le modèle détecte ensuite les individus de la classe frauduleuse de l'échantillon test comme nouvelles dans le sens différentes. Si tant est que ceux-ci se distinguent de la classe non frauduleuse par un comportement différent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52min 8s\n"
     ]
    }
   ],
   "source": [
    "%time Results_Novelty_rbf = Model_OneClassSVM(X_train = XTrain_0_scale, X_test = XTest_0_scale, yTest = yTest, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>nu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4577</td>\n",
       "      <td>1996</td>\n",
       "      <td>4924</td>\n",
       "      <td>735913</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.481739</td>\n",
       "      <td>0.997295</td>\n",
       "      <td>0.696333</td>\n",
       "      <td>0.993353</td>\n",
       "      <td>0.569491</td>\n",
       "      <td>0.995320</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4611</td>\n",
       "      <td>1962</td>\n",
       "      <td>6192</td>\n",
       "      <td>734645</td>\n",
       "      <td>0.989090</td>\n",
       "      <td>0.426826</td>\n",
       "      <td>0.997336</td>\n",
       "      <td>0.701506</td>\n",
       "      <td>0.991642</td>\n",
       "      <td>0.530732</td>\n",
       "      <td>0.994481</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4613</td>\n",
       "      <td>1960</td>\n",
       "      <td>6219</td>\n",
       "      <td>734618</td>\n",
       "      <td>0.989057</td>\n",
       "      <td>0.425868</td>\n",
       "      <td>0.997339</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>0.991605</td>\n",
       "      <td>0.530078</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4611</td>\n",
       "      <td>1962</td>\n",
       "      <td>6223</td>\n",
       "      <td>734614</td>\n",
       "      <td>0.989049</td>\n",
       "      <td>0.425605</td>\n",
       "      <td>0.997336</td>\n",
       "      <td>0.701506</td>\n",
       "      <td>0.991600</td>\n",
       "      <td>0.529787</td>\n",
       "      <td>0.994460</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4613</td>\n",
       "      <td>1960</td>\n",
       "      <td>6231</td>\n",
       "      <td>734606</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>0.425397</td>\n",
       "      <td>0.997339</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>0.991589</td>\n",
       "      <td>0.529712</td>\n",
       "      <td>0.994456</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4616</td>\n",
       "      <td>1957</td>\n",
       "      <td>6350</td>\n",
       "      <td>734487</td>\n",
       "      <td>0.988886</td>\n",
       "      <td>0.420937</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.702267</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.526370</td>\n",
       "      <td>0.994377</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4615</td>\n",
       "      <td>1958</td>\n",
       "      <td>6372</td>\n",
       "      <td>734465</td>\n",
       "      <td>0.988855</td>\n",
       "      <td>0.420042</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.702115</td>\n",
       "      <td>0.991399</td>\n",
       "      <td>0.525626</td>\n",
       "      <td>0.994361</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4615</td>\n",
       "      <td>1958</td>\n",
       "      <td>6375</td>\n",
       "      <td>734462</td>\n",
       "      <td>0.988851</td>\n",
       "      <td>0.419927</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.702115</td>\n",
       "      <td>0.991395</td>\n",
       "      <td>0.525537</td>\n",
       "      <td>0.994359</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4604</td>\n",
       "      <td>1969</td>\n",
       "      <td>6352</td>\n",
       "      <td>734485</td>\n",
       "      <td>0.988867</td>\n",
       "      <td>0.420226</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>0.700441</td>\n",
       "      <td>0.991426</td>\n",
       "      <td>0.525301</td>\n",
       "      <td>0.994367</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4606</td>\n",
       "      <td>1967</td>\n",
       "      <td>6358</td>\n",
       "      <td>734479</td>\n",
       "      <td>0.988862</td>\n",
       "      <td>0.420102</td>\n",
       "      <td>0.997329</td>\n",
       "      <td>0.700745</td>\n",
       "      <td>0.991418</td>\n",
       "      <td>0.525289</td>\n",
       "      <td>0.994365</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "3             4577           1996           4924          735913  0.990741   \n",
       "6             4611           1962           6192          734645  0.989090   \n",
       "12            4613           1960           6219          734618  0.989057   \n",
       "9             4611           1962           6223          734614  0.989049   \n",
       "15            4613           1960           6231          734606  0.989041   \n",
       "7             4616           1957           6350          734487  0.988886   \n",
       "8             4615           1958           6372          734465  0.988855   \n",
       "10            4615           1958           6375          734462  0.988851   \n",
       "14            4604           1969           6352          734485  0.988867   \n",
       "13            4606           1967           6358          734479  0.988862   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "3             0.481739            0.997295         0.696333         0.993353   \n",
       "6             0.426826            0.997336         0.701506         0.991642   \n",
       "12            0.425868            0.997339         0.701810         0.991605   \n",
       "9             0.425605            0.997336         0.701506         0.991600   \n",
       "15            0.425397            0.997339         0.701810         0.991589   \n",
       "7             0.420937            0.997343         0.702267         0.991429   \n",
       "8             0.420042            0.997341         0.702115         0.991399   \n",
       "10            0.419927            0.997341         0.702115         0.991395   \n",
       "14            0.420226            0.997326         0.700441         0.991426   \n",
       "13            0.420102            0.997329         0.700745         0.991418   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score      nu   gamma  \\\n",
       "3            0.569491           0.995320         0.8448  0.0065  0.0500   \n",
       "6            0.530732           0.994481         0.8466  0.0065  0.0100   \n",
       "12           0.530078           0.994464         0.8467  0.0065  0.0005   \n",
       "9            0.529787           0.994460         0.8466  0.0065  0.0050   \n",
       "15           0.529712           0.994456         0.8467  0.0065  0.0001   \n",
       "7            0.526370           0.994377         0.8468  0.0065  0.0100   \n",
       "8            0.525626           0.994361         0.8468  0.0065  0.0100   \n",
       "10           0.525537           0.994359         0.8468  0.0065  0.0050   \n",
       "14           0.525301           0.994367         0.8459  0.0065  0.0005   \n",
       "13           0.525289           0.994365         0.8461  0.0065  0.0005   \n",
       "\n",
       "    n_components  \n",
       "3              5  \n",
       "6              5  \n",
       "12             5  \n",
       "9              5  \n",
       "15             5  \n",
       "7             15  \n",
       "8             25  \n",
       "10            15  \n",
       "14            25  \n",
       "13            15  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Novelty_rbf.to_csv(\"C:/Users/jacky/OneDrive/Bureau/OSVM_RBF_nov.csv\")\n",
    "Results_Novelty_rbf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle à kernel sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle ayant les meilleures performances\n",
    "osvm = linear_model.SGDOneClassSVM(nu=0.0065, \n",
    "                                   fit_intercept=True, \n",
    "                                   random_state=2, \n",
    "                                   tol=1e-7, \n",
    "                                   max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "transform = Nystroem(kernel = 'rbf', \n",
    "                     gamma= 0.05, \n",
    "                     n_components = 5, \n",
    "                     random_state=2, \n",
    "                     degree = None, \n",
    "                     n_jobs = -2)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_osvm = delayed(pipeline_osvm.fit)(XTrain_0_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.05, n_components=5, n_jobs=-2,\n",
      "                          random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.0065, random_state=2,\n",
      "                                tol=1e-07))])\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_osvm.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele8_rbf_nov.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.05, n_components=5, n_jobs=-2,\n",
      "                          random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.0065, random_state=2,\n",
      "                                tol=1e-07))])\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.70      0.57      6573\n",
      "           1       1.00      0.99      1.00    740837\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.74      0.84      0.78    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4577   1996]\n",
      " [  4924 735913]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8448434745941278\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45431727.72 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep11 = deploiement_unsupervised(modele = \"modele8_rbf_nov.sav\", XTest = XTest_0_scale, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time Results_Novelty_poly = Model_OneClassSVM(X_train = XTrain_0_scale, X_test = XTest_0_scale, yTest = yTest, kernel = 'poly', degree = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>nu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4156</td>\n",
       "      <td>2417</td>\n",
       "      <td>1452</td>\n",
       "      <td>739385</td>\n",
       "      <td>0.994823</td>\n",
       "      <td>0.741084</td>\n",
       "      <td>0.996742</td>\n",
       "      <td>0.632284</td>\n",
       "      <td>0.998040</td>\n",
       "      <td>0.682374</td>\n",
       "      <td>0.997390</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4201</td>\n",
       "      <td>2372</td>\n",
       "      <td>1548</td>\n",
       "      <td>739289</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.730736</td>\n",
       "      <td>0.996802</td>\n",
       "      <td>0.639130</td>\n",
       "      <td>0.997910</td>\n",
       "      <td>0.681870</td>\n",
       "      <td>0.997356</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4302</td>\n",
       "      <td>2271</td>\n",
       "      <td>1787</td>\n",
       "      <td>739050</td>\n",
       "      <td>0.994571</td>\n",
       "      <td>0.706520</td>\n",
       "      <td>0.996937</td>\n",
       "      <td>0.654496</td>\n",
       "      <td>0.997588</td>\n",
       "      <td>0.679514</td>\n",
       "      <td>0.997262</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4128</td>\n",
       "      <td>2445</td>\n",
       "      <td>1617</td>\n",
       "      <td>739220</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.718538</td>\n",
       "      <td>0.996703</td>\n",
       "      <td>0.628024</td>\n",
       "      <td>0.997817</td>\n",
       "      <td>0.670239</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4210</td>\n",
       "      <td>2363</td>\n",
       "      <td>2082</td>\n",
       "      <td>738755</td>\n",
       "      <td>0.994053</td>\n",
       "      <td>0.669104</td>\n",
       "      <td>0.996812</td>\n",
       "      <td>0.640499</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.654489</td>\n",
       "      <td>0.997001</td>\n",
       "      <td>0.8188</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4297</td>\n",
       "      <td>2276</td>\n",
       "      <td>2613</td>\n",
       "      <td>738224</td>\n",
       "      <td>0.993459</td>\n",
       "      <td>0.621852</td>\n",
       "      <td>0.996926</td>\n",
       "      <td>0.653735</td>\n",
       "      <td>0.996473</td>\n",
       "      <td>0.637395</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4320</td>\n",
       "      <td>2253</td>\n",
       "      <td>2966</td>\n",
       "      <td>737871</td>\n",
       "      <td>0.993017</td>\n",
       "      <td>0.592918</td>\n",
       "      <td>0.996956</td>\n",
       "      <td>0.657234</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.623422</td>\n",
       "      <td>0.996476</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4238</td>\n",
       "      <td>2335</td>\n",
       "      <td>3081</td>\n",
       "      <td>737756</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.579041</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.644759</td>\n",
       "      <td>0.995841</td>\n",
       "      <td>0.610135</td>\n",
       "      <td>0.996343</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4192</td>\n",
       "      <td>2381</td>\n",
       "      <td>3429</td>\n",
       "      <td>737408</td>\n",
       "      <td>0.992226</td>\n",
       "      <td>0.550059</td>\n",
       "      <td>0.996782</td>\n",
       "      <td>0.637761</td>\n",
       "      <td>0.995371</td>\n",
       "      <td>0.590672</td>\n",
       "      <td>0.996076</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4364</td>\n",
       "      <td>2209</td>\n",
       "      <td>4248</td>\n",
       "      <td>736589</td>\n",
       "      <td>0.991361</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>0.997010</td>\n",
       "      <td>0.663928</td>\n",
       "      <td>0.994266</td>\n",
       "      <td>0.574778</td>\n",
       "      <td>0.995636</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "17            4156           2417           1452          739385  0.994823   \n",
       "16            4201           2372           1548          739289  0.994755   \n",
       "53            4302           2271           1787          739050  0.994571   \n",
       "14            4128           2445           1617          739220  0.994565   \n",
       "50            4210           2363           2082          738755  0.994053   \n",
       "15            4297           2276           2613          738224  0.993459   \n",
       "12            4320           2253           2966          737871  0.993017   \n",
       "9             4238           2335           3081          737756  0.992754   \n",
       "6             4192           2381           3429          737408  0.992226   \n",
       "51            4364           2209           4248          736589  0.991361   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "17            0.741084            0.996742         0.632284         0.998040   \n",
       "16            0.730736            0.996802         0.639130         0.997910   \n",
       "53            0.706520            0.996937         0.654496         0.997588   \n",
       "14            0.718538            0.996703         0.628024         0.997817   \n",
       "50            0.669104            0.996812         0.640499         0.997190   \n",
       "15            0.621852            0.996926         0.653735         0.996473   \n",
       "12            0.592918            0.996956         0.657234         0.995996   \n",
       "9             0.579041            0.996845         0.644759         0.995841   \n",
       "6             0.550059            0.996782         0.637761         0.995371   \n",
       "51            0.506735            0.997010         0.663928         0.994266   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score      nu   gamma  \\\n",
       "17           0.682374           0.997390         0.8152  0.0065  0.0001   \n",
       "16           0.681870           0.997356         0.8185  0.0065  0.0001   \n",
       "53           0.679514           0.997262         0.8260  0.0100  0.0001   \n",
       "14           0.670239           0.997260         0.8129  0.0065  0.0005   \n",
       "50           0.654489           0.997001         0.8188  0.0100  0.0005   \n",
       "15           0.637395           0.996700         0.8251  0.0065  0.0001   \n",
       "12           0.623422           0.996476         0.8266  0.0065  0.0005   \n",
       "9            0.610135           0.996343         0.8203  0.0065  0.0050   \n",
       "6            0.590672           0.996076         0.8166  0.0065  0.0100   \n",
       "51           0.574778           0.995636         0.8291  0.0100  0.0001   \n",
       "\n",
       "    n_components  \n",
       "17            25  \n",
       "16            15  \n",
       "53            25  \n",
       "14            25  \n",
       "50            25  \n",
       "15             5  \n",
       "12             5  \n",
       "9              5  \n",
       "6              5  \n",
       "51             5  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Novelty_poly.to_csv(\"C:/Users/jacky/OneDrive/Bureau/OSVM_POLY_nov.csv\")\n",
    "Results_Novelty_poly.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle à kernel polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle ayant les meilleures performances\n",
    "osvm = linear_model.SGDOneClassSVM(nu=0.0065, \n",
    "                                   fit_intercept=True, \n",
    "                                   random_state=2, \n",
    "                                   tol=1e-7, \n",
    "                                   max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "transform = Nystroem(kernel = 'poly', \n",
    "                     gamma= 0.0001, \n",
    "                     n_components = 25, \n",
    "                     random_state=2, \n",
    "                     degree = 5, \n",
    "                     n_jobs = -2)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_osvm = delayed(pipeline_osvm.fit)(XTrain_0_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(degree=5, gamma=0.0001, kernel='poly',\n",
      "                          n_components=25, n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.0065, random_state=2,\n",
      "                                tol=1e-07))])\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_osvm.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele8_poly_nov.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(degree=5, gamma=0.0001, kernel='poly',\n",
      "                          n_components=25, n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.0065, random_state=2,\n",
      "                                tol=1e-07))])\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.63      0.68      6573\n",
      "           1       1.00      1.00      1.00    740837\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.87      0.82      0.84    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4156   2417]\n",
      " [  1452 739385]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8151618195275772\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45863504.36 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep12 = deploiement_unsupervised(modele = \"modele8_poly_nov.sav\", XTest = XTest_0_scale, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50min 2s\n"
     ]
    }
   ],
   "source": [
    "%time Results_Novelty_sigmoid = Model_OneClassSVM(X_train = XTrain_0_scale, X_test = XTest_0_scale, yTest = yTest, kernel = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>nu</th>\n",
       "      <th>gamma</th>\n",
       "      <th>n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4314</td>\n",
       "      <td>2259</td>\n",
       "      <td>1486</td>\n",
       "      <td>739351</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.743793</td>\n",
       "      <td>0.996954</td>\n",
       "      <td>0.656321</td>\n",
       "      <td>0.997994</td>\n",
       "      <td>0.697325</td>\n",
       "      <td>0.997474</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4313</td>\n",
       "      <td>2260</td>\n",
       "      <td>1514</td>\n",
       "      <td>739323</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>0.740175</td>\n",
       "      <td>0.996952</td>\n",
       "      <td>0.656169</td>\n",
       "      <td>0.997956</td>\n",
       "      <td>0.695645</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4163</td>\n",
       "      <td>2410</td>\n",
       "      <td>1391</td>\n",
       "      <td>739446</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>0.749550</td>\n",
       "      <td>0.996751</td>\n",
       "      <td>0.633349</td>\n",
       "      <td>0.998122</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4212</td>\n",
       "      <td>2361</td>\n",
       "      <td>1487</td>\n",
       "      <td>739350</td>\n",
       "      <td>0.994852</td>\n",
       "      <td>0.739077</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.640803</td>\n",
       "      <td>0.997993</td>\n",
       "      <td>0.686441</td>\n",
       "      <td>0.997404</td>\n",
       "      <td>0.8194</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4200</td>\n",
       "      <td>2373</td>\n",
       "      <td>1547</td>\n",
       "      <td>739290</td>\n",
       "      <td>0.994755</td>\n",
       "      <td>0.730816</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.638978</td>\n",
       "      <td>0.997912</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.997356</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4216</td>\n",
       "      <td>2357</td>\n",
       "      <td>1597</td>\n",
       "      <td>739240</td>\n",
       "      <td>0.994710</td>\n",
       "      <td>0.725271</td>\n",
       "      <td>0.996822</td>\n",
       "      <td>0.641412</td>\n",
       "      <td>0.997844</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4138</td>\n",
       "      <td>2435</td>\n",
       "      <td>1541</td>\n",
       "      <td>739296</td>\n",
       "      <td>0.994680</td>\n",
       "      <td>0.728649</td>\n",
       "      <td>0.996717</td>\n",
       "      <td>0.629545</td>\n",
       "      <td>0.997920</td>\n",
       "      <td>0.675482</td>\n",
       "      <td>0.997318</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4240</td>\n",
       "      <td>2333</td>\n",
       "      <td>1785</td>\n",
       "      <td>739052</td>\n",
       "      <td>0.994490</td>\n",
       "      <td>0.703734</td>\n",
       "      <td>0.996853</td>\n",
       "      <td>0.645063</td>\n",
       "      <td>0.997591</td>\n",
       "      <td>0.673123</td>\n",
       "      <td>0.997222</td>\n",
       "      <td>0.8213</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4268</td>\n",
       "      <td>2305</td>\n",
       "      <td>2353</td>\n",
       "      <td>738484</td>\n",
       "      <td>0.993768</td>\n",
       "      <td>0.644616</td>\n",
       "      <td>0.996888</td>\n",
       "      <td>0.649323</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>0.646961</td>\n",
       "      <td>0.996856</td>\n",
       "      <td>0.8231</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4312</td>\n",
       "      <td>2261</td>\n",
       "      <td>3074</td>\n",
       "      <td>737763</td>\n",
       "      <td>0.992862</td>\n",
       "      <td>0.583807</td>\n",
       "      <td>0.996945</td>\n",
       "      <td>0.656017</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.617809</td>\n",
       "      <td>0.996397</td>\n",
       "      <td>0.8259</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "71            4314           2259           1486          739351  0.994989   \n",
       "53            4313           2260           1514          739323  0.994951   \n",
       "17            4163           2410           1391          739446  0.994914   \n",
       "16            4212           2361           1487          739350  0.994852   \n",
       "13            4200           2373           1547          739290  0.994755   \n",
       "70            4216           2357           1597          739240  0.994710   \n",
       "14            4138           2435           1541          739296  0.994680   \n",
       "50            4240           2333           1785          739052  0.994490   \n",
       "15            4268           2305           2353          738484  0.993768   \n",
       "12            4312           2261           3074          737763  0.992862   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "71            0.743793            0.996954         0.656321         0.997994   \n",
       "53            0.740175            0.996952         0.656169         0.997956   \n",
       "17            0.749550            0.996751         0.633349         0.998122   \n",
       "16            0.739077            0.996817         0.640803         0.997993   \n",
       "13            0.730816            0.996800         0.638978         0.997912   \n",
       "70            0.725271            0.996822         0.641412         0.997844   \n",
       "14            0.728649            0.996717         0.629545         0.997920   \n",
       "50            0.703734            0.996853         0.645063         0.997591   \n",
       "15            0.644616            0.996888         0.649323         0.996824   \n",
       "12            0.583807            0.996945         0.656017         0.995851   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score      nu   gamma  \\\n",
       "71           0.697325           0.997474         0.8272  0.0150  0.0001   \n",
       "53           0.695645           0.997454         0.8271  0.0100  0.0001   \n",
       "17           0.686567           0.997436         0.8157  0.0065  0.0001   \n",
       "16           0.686441           0.997404         0.8194  0.0065  0.0001   \n",
       "13           0.681818           0.997356         0.8184  0.0065  0.0005   \n",
       "70           0.680769           0.997333         0.8196  0.0150  0.0001   \n",
       "14           0.675482           0.997318         0.8137  0.0065  0.0005   \n",
       "50           0.673123           0.997222         0.8213  0.0100  0.0005   \n",
       "15           0.646961           0.996856         0.8231  0.0065  0.0001   \n",
       "12           0.617809           0.996397         0.8259  0.0065  0.0005   \n",
       "\n",
       "    n_components  \n",
       "71            25  \n",
       "53            25  \n",
       "17            25  \n",
       "16            15  \n",
       "13            15  \n",
       "70            15  \n",
       "14            25  \n",
       "50            25  \n",
       "15             5  \n",
       "12             5  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_Novelty_sigmoid.to_csv(\"C:/Users/jacky/OneDrive/Bureau/OSVM_SIGMOID_nov.csv\")\n",
    "Results_Novelty_sigmoid.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle à kernel sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle ayant les meilleures performances\n",
    "osvm = linear_model.SGDOneClassSVM(nu=0.015, \n",
    "                                   fit_intercept=True, \n",
    "                                   random_state=2, \n",
    "                                   tol=1e-7, \n",
    "                                   max_iter = 2000)\n",
    "\n",
    "# Kernel approximation\n",
    "transform = Nystroem(kernel = 'sigmoid', \n",
    "                     gamma= 0.0001, \n",
    "                     n_components = 25, \n",
    "                     random_state=2, \n",
    "                     degree = None, \n",
    "                     n_jobs = -2)\n",
    "\n",
    "# Pipeline\n",
    "pipeline_osvm = make_pipeline(transform, osvm)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_osvm = delayed(pipeline_osvm.fit)(XTrain_0_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.0001, kernel='sigmoid', n_components=25,\n",
      "                          n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.015, random_state=2,\n",
      "                                tol=1e-07))])\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_osvm.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele8_sigmoid_nov.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déploiement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " Pipeline(steps=[('nystroem',\n",
      "                 Nystroem(gamma=0.0001, kernel='sigmoid', n_components=25,\n",
      "                          n_jobs=-2, random_state=2)),\n",
      "                ('sgdoneclasssvm',\n",
      "                 SGDOneClassSVM(max_iter=2000, nu=0.015, random_state=2,\n",
      "                                tol=1e-07))])\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.66      0.70      6573\n",
      "           1       1.00      1.00      1.00    740837\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.87      0.83      0.85    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4314   2259]\n",
      " [  1486 739351]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8271577375635509\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45857845.51 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep13 = deploiement_unsupervised(modele = \"modele8_sigmoid_nov.sav\", XTest = XTest_0_scale, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------- Algorithme n°9 : ISOLATION FOREST --------¶\n",
    "\n",
    "L'algorithme Isolation Forest est semblable à Random Forest dans le sens où il est basé sur un ensemble d'arbres de décision, à la différence qu'il se concentre sur la détection d'outliers.\n",
    "Pour un échantillon défini et à chaque itération, il sélectionne au hasard une variable sur laquelle les observations sont comparées et classées, selon une valeur prise également aléatoirement. \n",
    "\n",
    "Les outliers sont des individus qui se distinguent fortement de l'ensemble de l'échantillon, ils sont donc détectés très rapidement. Ainsi, le nombre de branches pour atteindre une feuille (noeud terminal) sera sensiblement plus petit que ceux de la classe dominante.\n",
    "\n",
    "On souhaite optimiser la discrimination, on ne centre, ni ne réduit les données.\n",
    "On réalise un premier entraînement avec les paramètres par défaut.\n",
    "Le paramètre \"contamination\" représente la part d'outliers dans le jeu de données. On la fixe à 0.0065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsolaF = IsolationForest(n_jobs = -2, random_state = 2, contamination = 0.0065)\n",
    "\n",
    "#modélisation\n",
    "IsoF_fit = delayed(IsolaF.fit)(XTrain_ok)\n",
    "delayed_scoresIF = delayed(IsoF_fit.predict)(XTest_ok)\n",
    "\n",
    "#prédiction\n",
    "%time y_pred_IsoF = delayed_scoresIF.compute()\n",
    "\n",
    "#performance\n",
    "%time matriceIF = confusion_matrix(yTest, y_pred_IsoF)\n",
    "print(matriceIF)\n",
    "\n",
    "%time classifIF = classification_report(yTest, y_pred_IsoF)\n",
    "print(classifIF)\n",
    "\n",
    "print(round(roc_auc_score(yTest, y_pred_IsoF), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle ne donne pas de bons résultats. On va tester différents paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modele_IsolationForest(X_train, X_test, y_test):\n",
    "    \n",
    "    # Paramètres\n",
    "    n_estimators = [50, 100, 300]\n",
    "    max_samples = [50000, 300000, 'auto']\n",
    "    contamination = [0.0065, 0.009, 0.015, 0.2]\n",
    "    max_features = [1, 5, 16]\n",
    "\n",
    "    # Instanciation pour le stockage des résultats de performance\n",
    "    results_IF = []\n",
    "\n",
    "    # Tests de toutes les combinaisons\n",
    "    for n in n_estimators:\n",
    "        for s in max_samples:\n",
    "            for c in contamination:\n",
    "                for f in max_features:\n",
    "\n",
    "                    # Modèle\n",
    "                    IF = IsolationForest(\n",
    "                        n_estimators= n,\n",
    "                        max_samples= s,\n",
    "                        contamination= c,\n",
    "                        max_features = f,\n",
    "                        random_state = 2,\n",
    "                        n_jobs = -2\n",
    "                    )\n",
    "                    \n",
    "                    # Entraînement\n",
    "                    fit_if = delayed(IF.fit)(X_train)\n",
    "                    pred_if = delayed(fit_if.predict)(X_test)\n",
    "                    \n",
    "                    # Prédictions\n",
    "                    y_pred_IF = pred_if.compute()\n",
    "                    \n",
    "                    # Matrice de confusion\n",
    "                    cm_IF = delayed(confusion_matrix)(y_test, y_pred_IF).compute()\n",
    "\n",
    "                    # Stockage des résultats\n",
    "                    results_IF.append({'Vrais positifs' : cm_IF[0][0],\n",
    "                                       'Faux négatifs' : cm_IF[0][1],\n",
    "                                       'Faux positifs' : cm_IF[1][0],\n",
    "                                       'Vrais negatifs' : cm_IF[1][1],\n",
    "                                       'Accuracy': delayed(accuracy_score)(y_test, y_pred_IF).compute(),\n",
    "                                       'Precision classe 1' : delayed(precision_score)(y_test, y_pred_IF, pos_label = -1, average= 'binary', labels=np.unique(y_pred_IF)).compute(),\n",
    "                                       'Precision classe 0' : delayed(precision_score)(y_test, y_pred_IF, pos_label = 1, average= 'binary', labels=np.unique(y_pred_IF)).compute(),\n",
    "                                       'Rappel classe 1' : delayed(recall_score)(y_test, y_pred_IF, pos_label = -1, average= 'binary').compute(),\n",
    "                                       'Rappel classe 0' : delayed(recall_score)(y_test, y_pred_IF, pos_label = 1, average= 'binary').compute(),\n",
    "                                       'f1-score classe 1' : delayed(f1_score)(y_test, y_pred_IF, pos_label = -1, average= 'binary').compute(),\n",
    "                                       'f1-score classe 0' : delayed(f1_score)(y_test, y_pred_IF, pos_label = 1, average= 'binary').compute(),\n",
    "                                       'roc_auc_score' : round(roc_auc_score(y_test, y_pred_IF), 4),\n",
    "                                       'n_estimators': n,\n",
    "                                       'max_samples': s,\n",
    "                                       'contamination': c,\n",
    "                                       'max_features': f\n",
    "                                      })\n",
    "\n",
    "    # Convert to Pandas DataFrame and sort descendingly by accuracy\n",
    "    results_IF = pd.DataFrame(results_IF)\n",
    "    results_IF = results_IF.sort_values(by='f1-score classe 1', ascending=False)\n",
    "    return results_IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jacky\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8h 29min 2s\n"
     ]
    }
   ],
   "source": [
    "%time results_IsolationForest = modele_IsolationForest(X_train = XTrain_ok, X_test = XTest_ok, y_test = yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vrais positifs</th>\n",
       "      <th>Faux négatifs</th>\n",
       "      <th>Faux positifs</th>\n",
       "      <th>Vrais negatifs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision classe 1</th>\n",
       "      <th>Precision classe 0</th>\n",
       "      <th>Rappel classe 1</th>\n",
       "      <th>Rappel classe 0</th>\n",
       "      <th>f1-score classe 1</th>\n",
       "      <th>f1-score classe 0</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>contamination</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4307</td>\n",
       "      <td>2266</td>\n",
       "      <td>9713</td>\n",
       "      <td>731124</td>\n",
       "      <td>0.983973</td>\n",
       "      <td>0.307204</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.655256</td>\n",
       "      <td>0.986889</td>\n",
       "      <td>0.418297</td>\n",
       "      <td>0.991874</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>50</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3149</td>\n",
       "      <td>3424</td>\n",
       "      <td>5611</td>\n",
       "      <td>735226</td>\n",
       "      <td>0.987912</td>\n",
       "      <td>0.359475</td>\n",
       "      <td>0.995365</td>\n",
       "      <td>0.479081</td>\n",
       "      <td>0.992426</td>\n",
       "      <td>0.410748</td>\n",
       "      <td>0.993893</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>50</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4107</td>\n",
       "      <td>2466</td>\n",
       "      <td>9447</td>\n",
       "      <td>731390</td>\n",
       "      <td>0.984061</td>\n",
       "      <td>0.303010</td>\n",
       "      <td>0.996640</td>\n",
       "      <td>0.624829</td>\n",
       "      <td>0.987248</td>\n",
       "      <td>0.408109</td>\n",
       "      <td>0.991922</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>100</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2970</td>\n",
       "      <td>3603</td>\n",
       "      <td>5608</td>\n",
       "      <td>735229</td>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.346235</td>\n",
       "      <td>0.995123</td>\n",
       "      <td>0.451848</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.993775</td>\n",
       "      <td>0.7221</td>\n",
       "      <td>50</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3857</td>\n",
       "      <td>2716</td>\n",
       "      <td>9459</td>\n",
       "      <td>731378</td>\n",
       "      <td>0.983710</td>\n",
       "      <td>0.289652</td>\n",
       "      <td>0.996300</td>\n",
       "      <td>0.586794</td>\n",
       "      <td>0.987232</td>\n",
       "      <td>0.387853</td>\n",
       "      <td>0.991745</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>300</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3864</td>\n",
       "      <td>2709</td>\n",
       "      <td>9742</td>\n",
       "      <td>731095</td>\n",
       "      <td>0.983341</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>0.996308</td>\n",
       "      <td>0.587859</td>\n",
       "      <td>0.986850</td>\n",
       "      <td>0.382972</td>\n",
       "      <td>0.991557</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>100</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3815</td>\n",
       "      <td>2758</td>\n",
       "      <td>9620</td>\n",
       "      <td>731217</td>\n",
       "      <td>0.983439</td>\n",
       "      <td>0.283960</td>\n",
       "      <td>0.996242</td>\n",
       "      <td>0.580405</td>\n",
       "      <td>0.987015</td>\n",
       "      <td>0.381347</td>\n",
       "      <td>0.991607</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>300</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2867</td>\n",
       "      <td>3706</td>\n",
       "      <td>5608</td>\n",
       "      <td>735229</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.338289</td>\n",
       "      <td>0.994985</td>\n",
       "      <td>0.436178</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.381047</td>\n",
       "      <td>0.993706</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>100</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2874</td>\n",
       "      <td>3699</td>\n",
       "      <td>5638</td>\n",
       "      <td>735199</td>\n",
       "      <td>0.987508</td>\n",
       "      <td>0.337641</td>\n",
       "      <td>0.994994</td>\n",
       "      <td>0.437243</td>\n",
       "      <td>0.992390</td>\n",
       "      <td>0.381041</td>\n",
       "      <td>0.993690</td>\n",
       "      <td>0.7148</td>\n",
       "      <td>100</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3823</td>\n",
       "      <td>2750</td>\n",
       "      <td>10049</td>\n",
       "      <td>730788</td>\n",
       "      <td>0.982876</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>0.996251</td>\n",
       "      <td>0.581622</td>\n",
       "      <td>0.986436</td>\n",
       "      <td>0.373979</td>\n",
       "      <td>0.991319</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>50</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vrais positifs  Faux négatifs  Faux positifs  Vrais negatifs  Accuracy  \\\n",
       "20            4307           2266           9713          731124  0.983973   \n",
       "17            3149           3424           5611          735226  0.987912   \n",
       "56            4107           2466           9447          731390  0.984061   \n",
       "5             2970           3603           5608          735229  0.987676   \n",
       "92            3857           2716           9459          731378  0.983710   \n",
       "44            3864           2709           9742          731095  0.983341   \n",
       "80            3815           2758           9620          731217  0.983439   \n",
       "41            2867           3706           5608          735229  0.987538   \n",
       "53            2874           3699           5638          735199  0.987508   \n",
       "8             3823           2750          10049          730788  0.982876   \n",
       "\n",
       "    Precision classe 1  Precision classe 0  Rappel classe 1  Rappel classe 0  \\\n",
       "20            0.307204            0.996910         0.655256         0.986889   \n",
       "17            0.359475            0.995365         0.479081         0.992426   \n",
       "56            0.303010            0.996640         0.624829         0.987248   \n",
       "5             0.346235            0.995123         0.451848         0.992430   \n",
       "92            0.289652            0.996300         0.586794         0.987232   \n",
       "44            0.283992            0.996308         0.587859         0.986850   \n",
       "80            0.283960            0.996242         0.580405         0.987015   \n",
       "41            0.338289            0.994985         0.436178         0.992430   \n",
       "53            0.337641            0.994994         0.437243         0.992390   \n",
       "8             0.275591            0.996251         0.581622         0.986436   \n",
       "\n",
       "    f1-score classe 1  f1-score classe 0  roc_auc_score  n_estimators  \\\n",
       "20           0.418297           0.991874         0.8211            50   \n",
       "17           0.410748           0.993893         0.7358            50   \n",
       "56           0.408109           0.991922         0.8060           100   \n",
       "5            0.392053           0.993775         0.7221            50   \n",
       "92           0.387853           0.991745         0.7870           300   \n",
       "44           0.382972           0.991557         0.7874           100   \n",
       "80           0.381347           0.991607         0.7837           300   \n",
       "41           0.381047           0.993706         0.7143           100   \n",
       "53           0.381041           0.993690         0.7148           100   \n",
       "8            0.373979           0.991319         0.7840            50   \n",
       "\n",
       "   max_samples  contamination  max_features  \n",
       "20      300000          0.015            16  \n",
       "17      300000          0.009            16  \n",
       "56      300000          0.015            16  \n",
       "5        50000          0.009            16  \n",
       "92      300000          0.015            16  \n",
       "44       50000          0.015            16  \n",
       "80       50000          0.015            16  \n",
       "41       50000          0.009            16  \n",
       "53      300000          0.009            16  \n",
       "8        50000          0.015            16  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_IsolationForest.to_csv(\"C:/Users/jacky/OneDrive/Bureau/Isolation_Forest.csv\")\n",
    "results_IsolationForest.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle ne donne pas des prédictions satisfaisantes. En effet, la part de faux positifs est beaucoup trop importante. Cela pourrait s'expliquer par des caractéristiques très proches entre individus fraudeurs et non fraudeurs car cet algorithme se base sur une approche discriminante selon les caractéristiques fournies par les variables.\n",
    "On crée tout de même le modèle donnant les meilleurs caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle \n",
    "IF = IsolationForest(n_estimators= 50,\n",
    "                        max_samples= 300000,\n",
    "                        contamination= 0.015,\n",
    "                        max_features = 16,\n",
    "                        random_state = 2,\n",
    "                        n_jobs = -2)\n",
    "\n",
    "# Structure de l'entrainement\n",
    "fit_IF = delayed(IF.fit)(XTrain_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest(contamination=0.015, max_features=16, max_samples=300000,\n",
      "                n_estimators=50, n_jobs=-2, random_state=2)\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle entrainé \n",
    "model_fit = fit_IF.compute()\n",
    "print(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation du modèle \n",
    "f = open(\"modele9.sav\", \"wb\")\n",
    "pickle.dump(model_fit, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Modèle :\n",
      " IsolationForest(contamination=0.015, max_features=16, max_samples=300000,\n",
      "                n_estimators=50, n_jobs=-2, random_state=2)\n",
      "-------------------------------------------------------\n",
      "Estimateurs :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.31      0.66      0.42      6573\n",
      "           1       1.00      0.99      0.99    740837\n",
      "\n",
      "    accuracy                           0.98    747410\n",
      "   macro avg       0.65      0.82      0.71    747410\n",
      "weighted avg       0.99      0.98      0.99    747410\n",
      "\n",
      "-------------------------------------------------------\n",
      "Matrice de confusion :\n",
      " [[  4307   2266]\n",
      " [  9713 731124]]\n",
      "-------------------------------------------------------\n",
      "Auc Score :\n",
      " 0.8210727527482222\n",
      "-------------------------------------------------------\n",
      "Chiffre d'affaire = 45428474.29 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dep14 = deploiement_unsupervised(modele = \"modele9.sav\", XTest = XTest_ok, yTest = yTest, X_ca = XTest_ok, scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------- Algorithme n°10 : AUTOENCODER --------¶\n",
    "\n",
    "L'autoencoder est un algorithme non supervisé qui utilise un réseau de neurones pour reconstruire un jeu de données de grande dimension. Il identifie les caractéristiques discriminantes et constitue donc une solution potentiellement intéressante. Il réduit la dimensionnalité de l'échantillon dans les couches cachées, lors de l'apprentissage, puis reconstruit le jeu de données en essayant de prédire la variable cible en couche de sortie.\n",
    "\n",
    "\n",
    "Protocole :\n",
    "\n",
    "- Séparer le dataset de la façon suivante : \n",
    "    - Un pour l'outlier detection\n",
    "    - Un pour novelty detection \n",
    "\n",
    "- Entraînement sur les données conformes en testant différents paramètres\n",
    "\n",
    "- Evaluation des performances\n",
    "\n",
    "- Sélection du meilleur modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLIER DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de l'algorithme AutoEncoder du module pyOD\n",
    "from pyod.models.auto_encoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise un premier entraînement avec les paramètres suivants : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 14)                238       \n",
      "                                                                 \n",
      " dropout_98 (Dropout)        (None, 14)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 2)                 30        \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 2)                 6         \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 2)                 0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 14)                42        \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 14)                0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 16)                240       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,100\n",
      "Trainable params: 1,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "3428/3428 [==============================] - 9s 2ms/step - loss: 1.1668 - val_loss: 0.9977\n",
      "Epoch 2/5\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 1.0178 - val_loss: 0.9763\n",
      "Epoch 3/5\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 1.0057 - val_loss: 0.9720\n",
      "Epoch 4/5\n",
      "3428/3428 [==============================] - 7s 2ms/step - loss: 1.0036 - val_loss: 0.9714\n",
      "Epoch 5/5\n",
      "3428/3428 [==============================] - 8s 2ms/step - loss: 1.0033 - val_loss: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=1024, contamination=0.1, dropout_rate=0.2, epochs=5,\n",
       "      hidden_activation='relu', hidden_neurons=[14, 2, 2, 14],\n",
       "      l2_regularizer=0.1,\n",
       "      loss=<function mean_squared_error at 0x000002C1300CE5E0>,\n",
       "      optimizer='adam', output_activation='sigmoid', preprocessing=True,\n",
       "      random_state=None, validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement sur les données train avec une contamination de 0.1\n",
    "auto_name = 'AutoEncoder'\n",
    "auto = AutoEncoder(epochs=5, \n",
    "                   contamination=0.1, \n",
    "                   hidden_neurons =[14, 2, 2, 14], \n",
    "                   batch_size = 1024)\n",
    "auto.fit(XTrain_ok_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle affecte une classe aux individus de l'échantillon d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes affectées aux individus de par le modèle\n",
    "y_label_ae = auto.labels_\n",
    "y_label_ae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réalise les prédictions sur les données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest = yTest.replace({-1: 1, 1 : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[668193  72644]\n",
      " [  1343   5230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    740837\n",
      "           1       0.07      0.80      0.12      6573\n",
      "\n",
      "    accuracy                           0.90    747410\n",
      "   macro avg       0.53      0.85      0.54    747410\n",
      "weighted avg       0.99      0.90      0.94    747410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction\n",
    "y_test_pred = auto.predict(XTest_ok_scale)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_ae = confusion_matrix(yTest, y_test_pred)\n",
    "print(cm_ae)\n",
    "\n",
    "# Rapport de classification\n",
    "cf_ae = classification_report(yTest, y_test_pred)\n",
    "print(cf_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont mauvais pour la classe frauduleuse. Le taux de contamination est trop élevé. \n",
    "On tente de nouveau en jouant sur plus de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_126 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 64)                1088      \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 16)                0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 64)                1088      \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,072\n",
      "Trainable params: 5,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "3428/3428 [==============================] - 16s 4ms/step - loss: 0.9773 - val_loss: 0.3506\n",
      "Epoch 2/15\n",
      "3428/3428 [==============================] - 18s 5ms/step - loss: 0.3195 - val_loss: 0.2897\n",
      "Epoch 3/15\n",
      "3428/3428 [==============================] - 20s 6ms/step - loss: 0.2759 - val_loss: 0.2604\n",
      "Epoch 4/15\n",
      "3428/3428 [==============================] - 20s 6ms/step - loss: 0.2591 - val_loss: 0.2548\n",
      "Epoch 5/15\n",
      "3428/3428 [==============================] - 20s 6ms/step - loss: 0.2562 - val_loss: 0.2533\n",
      "Epoch 6/15\n",
      "3428/3428 [==============================] - 20s 6ms/step - loss: 0.2552 - val_loss: 0.2526\n",
      "Epoch 7/15\n",
      "3428/3428 [==============================] - 20s 6ms/step - loss: 0.2548 - val_loss: 0.2522\n",
      "Epoch 8/15\n",
      "3428/3428 [==============================] - 21s 6ms/step - loss: 0.2545 - val_loss: 0.2520\n",
      "Epoch 9/15\n",
      "3428/3428 [==============================] - 22s 6ms/step - loss: 0.2543 - val_loss: 0.2518\n",
      "Epoch 10/15\n",
      "3428/3428 [==============================] - 20s 6ms/step - loss: 0.2542 - val_loss: 0.2516\n",
      "Epoch 11/15\n",
      "3428/3428 [==============================] - 18s 5ms/step - loss: 0.2541 - val_loss: 0.2515\n",
      "Epoch 12/15\n",
      "3428/3428 [==============================] - 15s 4ms/step - loss: 0.2541 - val_loss: 0.2515\n",
      "Epoch 13/15\n",
      "3428/3428 [==============================] - 15s 4ms/step - loss: 0.2540 - val_loss: 0.2514\n",
      "Epoch 14/15\n",
      "3428/3428 [==============================] - 15s 4ms/step - loss: 0.2540 - val_loss: 0.2513\n",
      "Epoch 15/15\n",
      "3428/3428 [==============================] - 15s 4ms/step - loss: 0.2539 - val_loss: 0.2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=1024, contamination=0.0065, dropout_rate=0.5,\n",
       "      epochs=15, hidden_activation='softmax',\n",
       "      hidden_neurons=[64, 16, 16, 64], l2_regularizer=0.9,\n",
       "      loss='BinaryCrossentropy', optimizer='adam',\n",
       "      output_activation='sigmoid', preprocessing=False, random_state=2,\n",
       "      validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement sur les données train\n",
    "auto_name = 'AutoEncoder'\n",
    "auto = AutoEncoder(epochs=15, \n",
    "                   contamination=0.0065, \n",
    "                   hidden_neurons =[64, 16, 16, 64],\n",
    "                   hidden_activation = 'softmax',\n",
    "                   batch_size = 1024,\n",
    "                   dropout_rate = 0.5,\n",
    "                   random_state = 2,\n",
    "                   l2_regularizer = 0.9,\n",
    "                   loss = 'BinaryCrossentropy',\n",
    "                   preprocessing = False)\n",
    "\n",
    "auto.fit(XTrain_ok_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[737620   3217]\n",
      " [  2826   3747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    740837\n",
      "           1       0.54      0.57      0.55      6573\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.77      0.78      0.77    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction\n",
    "y_test_pred = auto.predict(XTest_ok_scale)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_ae = confusion_matrix(yTest, y_test_pred)\n",
    "print(cm_ae)\n",
    "\n",
    "# Rapport de classification\n",
    "cf_ae = classification_report(yTest, y_test_pred)\n",
    "print(cf_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons un f1_score assez moyen pour la classe frauduleuse. De plus nous voyons que l'erreur stagne à partir de la 7ème epoch. Nous essayons avec différents paramètres. Plus de couches cachées, les fonctions d'activation de la couche cachée et du décoder seront la sigmoid, qui donnait de bons résultats avec One Class SVM. On diminue légèrement le taux de dropout à 0.4 ainsi que le l2_regularizer de 0.9 à 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                1088      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                144       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,216\n",
      "Trainable params: 8,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "4570/4570 [==============================] - 21s 4ms/step - loss: 2.5910 - val_loss: 0.4465\n",
      "Epoch 2/15\n",
      "4570/4570 [==============================] - 20s 4ms/step - loss: 0.2346 - val_loss: 0.1127\n",
      "Epoch 3/15\n",
      "4570/4570 [==============================] - 20s 4ms/step - loss: 0.0786 - val_loss: 0.0618\n",
      "Epoch 4/15\n",
      "4570/4570 [==============================] - 20s 4ms/step - loss: 0.0580 - val_loss: 0.0557\n",
      "Epoch 5/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0547 - val_loss: 0.0540\n",
      "Epoch 6/15\n",
      "4570/4570 [==============================] - 20s 4ms/step - loss: 0.0535 - val_loss: 0.0531\n",
      "Epoch 7/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0439 - val_loss: 0.0376\n",
      "Epoch 8/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0377 - val_loss: 0.0372\n",
      "Epoch 9/15\n",
      "4570/4570 [==============================] - 22s 5ms/step - loss: 0.0373 - val_loss: 0.0369\n",
      "Epoch 10/15\n",
      "4570/4570 [==============================] - 22s 5ms/step - loss: 0.0371 - val_loss: 0.0367\n",
      "Epoch 11/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 12/15\n",
      "4570/4570 [==============================] - 22s 5ms/step - loss: 0.0367 - val_loss: 0.0365\n",
      "Epoch 13/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0366 - val_loss: 0.0364\n",
      "Epoch 14/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 15/15\n",
      "4570/4570 [==============================] - 21s 5ms/step - loss: 0.0364 - val_loss: 0.0362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=768, contamination=0.0065, dropout_rate=0.4, epochs=15,\n",
       "      hidden_activation='sigmoid',\n",
       "      hidden_neurons=[64, 32, 16, 8, 16, 32, 64], l2_regularizer=0.4,\n",
       "      loss='BinaryCrossentropy', optimizer='adam',\n",
       "      output_activation='sigmoid', preprocessing=False, random_state=2,\n",
       "      validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement sur les données train\n",
    "auto_name = 'AutoEncoder'\n",
    "auto_outl = AutoEncoder(epochs=15, \n",
    "                   contamination=0.0065, \n",
    "                   hidden_neurons =[64, 32, 16, 8, 16, 32, 64],\n",
    "                   hidden_activation = 'sigmoid',\n",
    "                   batch_size = 768,\n",
    "                   dropout_rate = 0.4,\n",
    "                   random_state = 2,\n",
    "                   l2_regularizer = 0.4,\n",
    "                   loss = 'BinaryCrossentropy',\n",
    "                   output_activation = 'sigmoid',\n",
    "                   preprocessing = False)\n",
    "\n",
    "auto_outl.fit(XTrain_ok_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[737620   3217]\n",
      " [  2826   3747]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    740837\n",
      "           1       0.54      0.57      0.55      6573\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.77      0.78      0.77    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction\n",
    "y_test_pred = auto_outl.predict(XTest_ok_scale)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_ae = confusion_matrix(yTest, y_test_pred)\n",
    "print(cm_ae)\n",
    "\n",
    "# Rapport de classification\n",
    "cf_ae = classification_report(yTest, y_test_pred)\n",
    "print(cf_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7828584739653154"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yTest, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont quasiment similaires malgré la modification des paramètres. L'algorithme ne semble pas en mesure de faire mieux qu'une performance de prédiction légèrement supérieure à la moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcul_CA_AE(Montant, yReel, yPred):\n",
    "    # Création de dfmerge\n",
    "    dfmerge = pd.concat([Montant, yReel], axis=1)\n",
    "    dfmerge[\"Ypred\"] = yPred\n",
    "    \n",
    "    # Création de la variable CA\n",
    "    dfmerge[\"CA\"] = dfmerge[\"Montant\"]\n",
    "    dfmerge.loc[((dfmerge[\"FlagImpaye\"] == 1) & (dfmerge[\"Ypred\"] == 1)), \"CA\"] = 0\n",
    "    dfmerge.loc[((dfmerge[\"FlagImpaye\"] == 0) & (dfmerge[\"Ypred\"] == 1)), \"CA\"] = 0.8 * dfmerge[\"Montant\"]\n",
    "    dfmerge.loc[((dfmerge[\"FlagImpaye\"] == 1) & (dfmerge[\"Ypred\"] == 0)), \"CA\"] = 1 - np.exp(1/dfmerge[\"Montant\"])\n",
    "    \n",
    "    # Calcul du CA_total\n",
    "    CA_total = dfmerge[\"CA\"].sum()\n",
    "    \n",
    "    return CA_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiffre d'affaire = 45493649.31 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# BONUS :  Calcul du chiffre d'affaires\n",
    "CA_total = Calcul_CA_AE(Montant = XTest_ok[\"Montant\"].compute(), yReel = yTest.compute(), yPred = y_test_pred)\n",
    "print(\"Chiffre d'affaire = \" + str(round(CA_total, 2)) + \" euros\")\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOVELTY DETECTION\n",
    "\n",
    "Comme pour One Class SVM, on entraîne uniquement sur la classe non frauduleuse et on prédit sur les deux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                1088      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                144       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                544       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,216\n",
      "Trainable params: 8,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "4543/4543 [==============================] - 22s 5ms/step - loss: 1.3630 - val_loss: 0.2089\n",
      "Epoch 2/15\n",
      "4543/4543 [==============================] - 21s 5ms/step - loss: -13.1056 - val_loss: -29.8068\n",
      "Epoch 3/15\n",
      "4543/4543 [==============================] - 21s 5ms/step - loss: -43.0395 - val_loss: -56.9955\n",
      "Epoch 4/15\n",
      "4543/4543 [==============================] - 21s 5ms/step - loss: -69.5489 - val_loss: -83.3168\n",
      "Epoch 5/15\n",
      "4543/4543 [==============================] - 22s 5ms/step - loss: -95.7249 - val_loss: -109.5597\n",
      "Epoch 6/15\n",
      "4543/4543 [==============================] - 21s 5ms/step - loss: -121.8565 - val_loss: -135.7919\n",
      "Epoch 7/15\n",
      "4543/4543 [==============================] - 22s 5ms/step - loss: -148.0311 - val_loss: -162.0360\n",
      "Epoch 8/15\n",
      "4543/4543 [==============================] - 27s 6ms/step - loss: -174.1862 - val_loss: -188.2911\n",
      "Epoch 9/15\n",
      "4543/4543 [==============================] - 23s 5ms/step - loss: -200.3704 - val_loss: -214.5437\n",
      "Epoch 10/15\n",
      "4543/4543 [==============================] - 23s 5ms/step - loss: -226.5548 - val_loss: -240.7868\n",
      "Epoch 11/15\n",
      "4543/4543 [==============================] - 22s 5ms/step - loss: -252.7236 - val_loss: -267.0412\n",
      "Epoch 12/15\n",
      "4543/4543 [==============================] - 24s 5ms/step - loss: -278.8750 - val_loss: -293.3010\n",
      "Epoch 13/15\n",
      "4543/4543 [==============================] - 27s 6ms/step - loss: -305.1737 - val_loss: -319.5564\n",
      "Epoch 14/15\n",
      "4543/4543 [==============================] - 27s 6ms/step - loss: -331.3432 - val_loss: -345.8002\n",
      "Epoch 15/15\n",
      "4543/4543 [==============================] - 30s 7ms/step - loss: -357.5460 - val_loss: -372.0873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(batch_size=768, contamination=0.0065, dropout_rate=0.4, epochs=15,\n",
       "      hidden_activation='sigmoid',\n",
       "      hidden_neurons=[64, 32, 16, 8, 16, 32, 64], l2_regularizer=0.2,\n",
       "      loss='BinaryCrossentropy', optimizer='adam',\n",
       "      output_activation='sigmoid', preprocessing=False, random_state=2,\n",
       "      validation_size=0.1, verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement sur les données train \n",
    "auto_name = 'AutoEncoder'\n",
    "auto_nov = AutoEncoder(epochs=15, \n",
    "                   contamination=0.0065, \n",
    "                   hidden_neurons =[64, 32, 16, 8, 16, 32, 64],\n",
    "                   hidden_activation = 'sigmoid',\n",
    "                   batch_size = 768,\n",
    "                   dropout_rate = 0.4,\n",
    "                   random_state = 2,\n",
    "                   l2_regularizer = 0.2,\n",
    "                   loss = 'BinaryCrossentropy',\n",
    "                   output_activation = 'sigmoid',\n",
    "                   preprocessing = False)\n",
    "\n",
    "auto_nov.fit(XTrain_0_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[734614   6223]\n",
      " [  1958   4615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    740837\n",
      "           1       0.43      0.70      0.53      6573\n",
      "\n",
      "    accuracy                           0.99    747410\n",
      "   macro avg       0.71      0.85      0.76    747410\n",
      "weighted avg       0.99      0.99      0.99    747410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prédiction\n",
    "y_test_pred_nov = auto_nov.predict(XTest_0_scale)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm_ae = confusion_matrix(yTest, y_test_pred_nov)\n",
    "print(cm_ae)\n",
    "\n",
    "# Rapport de classification\n",
    "cf_ae = classification_report(yTest, y_test_pred_nov)\n",
    "print(cf_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468573766369868"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yTest, y_test_pred_nov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mode semi-supervisé (novelty detection), le modèle est nettement plus performant sur les bonnes prédictions, ce qui augmente le rappel. Il pêche cependant sur les faux positifs. De manière semblable à l'isolation forest, ici les caractéristiques de certaines transactions se ressemblent, la probabilité qu'elles sont dans la même classe augmente donc également.\n",
    "Si les bonnes prédictions sont meilleures qu'en non supervisé, les faux positifs sont bien trop importants. Cela se répercute sur la f1-score de la classe fraduleuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiffre d'affaire = 45396211.39 euros\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# BONUS :  Calcul du chiffre d'affaire\n",
    "CA_total_nov = Calcul_CA_AE(Montant = XTest_ok[\"Montant\"].compute(), yReel = yTest.compute(), yPred = y_test_pred_nov)\n",
    "print(\"Chiffre d'affaire = \" + str(round(CA_total_nov, 2)) + \" euros\")\n",
    "print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compare les CA générés par les 9 algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABEiUlEQVR4nO3deZxbdbn48c8z+550mdIlQ0tbSoF2UqDsiwhylUVARQUFEeFycUW57j8vKlfv9edPvaioiCAgKIiIy0VwB6UtUgvMDC2FMl1g0n2mzaydNc/vj3MyTYfJJLMkJ8vzfr3ymknOSfIkk8lzvsv5PqKqGGOMMaMp8DoAY4wxmcuShDHGmLgsSRhjjInLkoQxxpi4LEkYY4yJy5KEMcaYuCxJmGEiskFEzvbw+ReIiIpIkVcxTISIHCkiTSJyRKrvKyK1ItIgIieMP9LUEpGzRSTkdRxeEpH3i8iqmOvTReSfInLKKPveIyJfSW+E42dJYgJE5D0isk5EukRkp4g8LiJneB3XZKnqsar6pNdxTJSI1IjIrSLymvu3aXavzxyx35Misl9ESqfgOX3Aj4DLVHVrKu8rIsXAvcCHVPXZicRr0ktV9wEXAV8TkTqv45kISxLjJCI3AbcC/wUcBhwOfB+4xMOwEsq2o/PxEpES4C/AscBbgBrgNKANOClmvwXAmYACF0/2eVW1XVXPVtVNqbivOArc/QdU9QJVXTOZmMdDRArT9Vy5SlV3u3/nFq9jmRBVtUuSF8AHdAHvHGOfUpwkssO93AqUutvOBkLAp4E9wE7gUuACYBOwD/h8zGN9CXgY+DnQCTwHBGO2fxbY7G57EXhbzLb3A6uB/3Ef9yvAIuCvOF+crcBPAX/MfbYBb3J/PwlYB3QAu4Fvxex3MbABCANPAkePeIxPAk1Auxt7WZz3qhD4hhvLFuDDOF/eRSPjiXk/7o/zWNe5cVYl+Bve7L4v3wIeTbDvEcDf3ff3z8D3Yp8fOAVY474PjcDZMdueBP7Tfa5O4I/AzHHc96vufQ8Ai4GlwJ/cv+XLwLvGiPtJ4L+Bte7f4DfA9JjtvwB2udv+Dhwbs+0e4AfAY0B37Psfs8904G6cz/d+4NcjPt//zsHP9zUx97sQeN79TLUAXxrxuFcBr+J8Pv8Ph34e7wG+ErPv2UAo5vpc4JfAXmAr8LEx3p97cA7sHsf5f14NzMb5X90PvAQcF7P/0e57Gsb53F8cs20G8Fv3Na11/+arYrbH/t02AZePiCP2NV0ENLjPswao9/L7bjgurwPIpgvOEeog7pdYnH1uAf4BzAJq3T/2f7rbznbvfzNQDPyr+6H+GVCNcxTcCyx09/8SMABc5u7/SfcfoNjd/k73n6MAeLf7Tz3H3fZ+97k+ChQB5ThfNufhJLJanC+IW2Nij/2nfBq4yv29CjjF/X2J+zznuTF9GmgGSmIeY60b13RgI3BDnPfqBvcfss7d9wkmniQeBO5N4m/YDHwIOMF9bw8bY9+ncZJYCXAGzhfB/e62eThfZhe47/957vVad/uTOAl8ifvePwl8bRz3fc39PBThHJy0ANe414/HSazHxon7SWA7sAyoxPnyjE1uH8D5vEUPaBpitt2DkzxOd2N7XYIHfoeT/Ke5n4E3jPh83+LefgHQA0yL2b7cfdx6nKR+qbvtGJwv7LPcuL7lPlbCJOE+3rM4/1clwEKcg443x3l/7nHfvxOAMpwDp63A+3AOXL4CPOHuW4zzmfm8+9jn4CT9o2I+dw+57/My931f5W6rdP9u17l/txNwksXyka/J/ZvuAU52Y7ga5/Nf6vn3ntcBTPkLgh+7b/b6JPb9H5zM3YCT5cMJ9n8vsCvBPpuBC2KuvxnYFvPBPgAUutercb4UT47Z/9mYf5wvAf+I2VaAc3R2ZpznbgAucX9/P/BaglgvBZ6Pub4t5p/y78CXiTn6dW//D+ChETFtxz0Sdh/jypjtXwduj/P8fyUmgQD/wsSTxJ9wv4THeL1n4CSGme71l4BPxNn3cJwvqYqY2+7nYJL4DHDfiPv8Abja/f1J4Asx2z4E/H4c970lZtu7gadG7P9D4ItxYn8y9r3A+QLuj37uRuzrd99zn3v9HuAnY7yHc4AI7hf/iG1n43y+i2Ju24N7gDHK/rcC/+P+fjPwYMy2SjfmZJLEyYz4rAOfA+6O87z3AD+Kuf5RYGPM9eW43wU4XZO7gIKY7Q+4n8VC9/O0NGbbf3EwSbwbWD3iue/AbUFxaJL4Ae7BZMy+L+MmYC8vuTgmcQ/OEX9CqvoJVV2hqiuA7wKPJLhLGzAzQf/+XJwmc9Sr7m3Dj6GqQ+7vB9yfu2O2H8A5co8a7sdU1QhOc34ugIi8z53pEhaRMM6RzMzR7uvuP0tEHhSR7SLSgfOld8igboxrcY6CX3JnZ1w02utzY2rBOTqO2hXze8+I1xNr7ogYX42zXzLacL7AxnI18EdVbXWv/8y9LV5s+1S1J+a22FjnA++Mvvfu+3/GiBjivQ/J3Hfkc508Yv/34nSRxDPyfS3G+ewWisjXRGSz+xnY5u4T93MzQh3O+7I/zvY2VR2MuT78ukXkZBF5QkT2ikg7Tksy+ryHfBZUtRvnb5qM+cDcEe/P53HGDOMZ+T8X739wLtDifs6jXsX5vNfitBDifYbnA8tE5KXoBee7aVqc1/DvI15DHYd+d3gi5wYzVfXv7uDkMBFZhNOfXIvzof1XVX1pxF2vAL6Y4OGfxukOuhRnrGA0O3D+4Bvc64e7t03U8IwIdwAzAOwQkfk4M2POBZ5W1SERaQAk5r464rH+272tXlXbRORS4LbRnlRVXwGucJ/z7cDDIjLDfS3LY2ISN8btE3htO2NfH857FasbqIi5PtaX4p+Br4hIpfsFcwgRKQfeBRSKSPTLuxTwi0hQVRtHiW26iFTEJIrYWFtwWgP/OkZM8SRz39i/XQvwN1U9bxzPMfJ9HcDpYnkPziSLN+EkCB9OP/xYn5tYLTjvi19Vw+OIB5ykfBtwvqr2isitHEwSO3H6/gEQkQqc/v6osT4LLcBWVT1ynPEkYwdQJyIFMYnicJyeh704rc06nFZpdFtsXOtU9dwknqcF+KqqfnVqwp46udiSGM0dwEdV9QScfv3vx250v3CPwOn+iEtV23Gaxd8TkUtFpEJEikXkfBH5urvbA8AX3PnsM939759E7CeIyNvd1svHgT6cMY9KnH/mve5ruAanJTGWapx+37CIzAM+FW9HEblSRGrdf4ywe/MQTv/rhSJyrjsl89/dmCYy4+Yh4GMiEhCRaTgD8bEagMvd93glzthMPPfh/KP9UkSWikiBiMwQkc+LyAU4iX0Ip+tlhXs5GngKpy/6EKr6Ks7A/ZdEpERETgXeGrPL/cBbReTN7tF5mXueQCCJ1z3e+z4KLBGRq9z3olhEThSRo+PsD3CliBzjftneAjzstmCrcf5ebThfuv+VRLzDVHUnzoDv90VkmhvLWUnevRqnFdIrIifhJKyoh4GLROQMd6baLRz6/dQAXCDOeQezcf4XotYCHSLyGREpd9/TZSJy4nheWxzP4CSoT7uv9Wycz8GD7vv5CM5npEJEjuHQlumjwJHinDtRkuDv9iPgBre1JSJSKSIXikj1FLyGScn5JCEiVThTIX/hHmn/kNd3S1zOwX+iManqt4CbgC/gfEG3AB8Bfu3u8hWcL5cm4AWcGUmTOWHmNzh9m/txZn+8XZ2pkC8C38Rp3ezGObpfneCxvowzQNaOM/g4VvfaW4ANItIFfBtnVkavqr4MXInTPdeK8w/zVlXtn8Br+xFOX3wjzvs0Mp7/wJmRtd+N/WfxHkhV+3COjl/CGZ+IzjaZifOPfjVOH/VrqroresE5sn2vjN6F+F7gVJwv1K/gDNb2uc/XgnNE/nkOfg4+RRL/U+O9r6p24ozXXI5zZLsL+L84LaF47sPpet2FMzj7Mff2n+B0iWzHmRH3j0TxjuIqnJbJSzhjDh9P8n4fAm4RkU6cg6eHohtUdQPO7Laf4bQq9uN0rca+nkac1s8fcf4W0fsO4XwOV+AMQLcCd+K0kibF/VxfDJzvPu73gffF9ER8BKdrahfO+313zH07cSYlvBPn/Y77d1PVdTgTWW7Dee3NOOOKnhN3gCSnuN1Nj6rqMhGpAV5W1bj91SLyPPBhTeP882SIyJeAxap6pdexGBCRnwMvqWqibklPiciTOAPsd3ody2SIyDbgOlX9s9ex5LOcb0moagewVUTeCcMnJwWj20XkKJyBpKc9CtFkKLdrYJHbdfUWnKP/X3scljFplXNJQkQewPnCP0pEQiJyLU63wbUi0ogzoHxJzF2uwOlfzL0mlZms2TjTSbuA7wAfVNXnPY3ImDTLye4mY4wxUyPnWhLGGGOmTk6dJzFz5kxdsGCB12EYY0xWefbZZ1tVtXa0bTmVJBYsWMC6deu8DsMYY7KKiMRd7cC6m4wxxsRlScIYY0xcliSMMcbEZUnCGGNMXJYkjDHGxGVJwhhjTFyWJIwxxsSVU+dJ5KLO3gH6ByMMqRKJQESVoYiO+Mkhtzn7xv7OKLc5P2Mf4/W3jdgec9u0imKuPm0BTs0hk4iq2ntlspIliQz2aNMOPvKzzF1P7vj506gP+L0OI+O9uKODS7+/mkIRasqLqCkrpqa8GF95MTVlRdSUF7u3Hdz2+utFFBVaw9+knyWJDPaHDbuZWVXCR885koICoVCEwgIoEKGwwLlEfz94W8x2EQqGtzHKvjJiXw653/DP2O0i7Gzv5cyvP0FjqN2SRBJWNe+lfzDC+09bwIH+ITp6B2g/MMCezl6a9wzS0TtAx4EBIgnW2qwsKYybQEbe7is/NNlUlxVTWGAtGTN+liQyVCSirGlu5awltVx92gKvwzlEYFo5MypLaGoJwynzvQ4n4zWG2pnnL+dLFx8bdx9Vpbt/iI4DA27SGIz5fYCO3kHaDwwcsn1XRy+b9nQ6+/YOkGhB56rSotcllNrqUj77lqPxVRRP8as2ucKSRIZ6eXcnbd39nL54ZuKd00xEqA/4aAyFvQ4lKzS2hFlR5x9zHxGhqrSIqtIi5lI+7ueIRJTu/kE6et3kEiexHEw6A7TsO8CfN+7hxAXTefvxyZTmNvnIkkSGWt3cCsDpi2d4HMnognV+/rZpL919g1SW2sconrauPkL7D3BViltcBQVCdVkx1WXFzPMnl2SGIsryL/2BxpawJQkTl42EZajVza0snFnJHN/4jyrTIRjwE1FYv73d61AyWlPIeX+CCVoSXigsEJbP89EQsr+hic+SRAYaGIrwzNZ9GdnVFFUf8AFYl1MCjaEwIrBsns/rUEa1os7Pxh0d9A9GvA7FZChLEhmooSVMT/9QxnY1AcyoKiUwrZxGOwodU2NLmCNnVVGVoV1y9QE//UMRXtrV4XUoJkNZkshAq5tbEYFTF2ZuSwKcLqcma0nEpao0Zfg04WCd2yJsCXsbiMlYliQy0OrmVpbP82X8tMT6gI+WfQdo6+rzOpSMFNp/gLbu/owcj4ia5y9nZlUJDS3WIjSjsySRYbr7Bnn+tTCnLcrsVgQcHIxtssHrUQ0PWgcyczwCnKm31iI0Y7EkkWHWbtvHYEQ5I4MHraOWzfMhAk12FDqqplCYksICls6u8TqUMdUH/DTv7aKzd8DrUEwGsiSRYVa/0kpJUQErF0zzOpSEqkqLWFxbZUehcTS0hDl6bg0lRZn9bxas86EKL1iL0Iwisz+9eWj15jZWzp9GWXGh16EkJVjnpzEURhOtCZFnhiLK+u3tGd3VFBV0B9YbrUVoRmFJIoO0dfWxcWdHRp8fMVIw4KO1q58d7b1eh5JRNu/tort/aPgLOJNNqyxh/owKm+FkRmVJIoOs2dwGwGmLMvf8iJGi0zub7AvmENEv3OgU00xXb4PXJg5LEhlkzeZWqsuKWJ6hZ+eOZumcaooLhQb7gjlEYyhMVWkRC2dWeR1KUoIBHzvae9nTYS1CcyhLEhlkVXMrpyyckVXFZUqLCjlmTo3NcBqhKdTO8nk+CrKkhkN0lVo7g96MlD3fRjmuZV8PLfsOcHoWdTVF1Qf8vLC9nUiiqjl5om9wiI07OzL6JLqRjp3ro7BAbFzCvI4liQwRXRr8jCOzZ9A6qj7go6tvkC2tXV6HkhE27uxkYEizYmZTVHlJIUsOq7YFG83rWJLIEKuaW5lVXcqi2uzow4413FVhXU5A7KC139M4xmtFnY/GFpvObA5lSSIDRCLK05vbOGPxTESyow871sLaKipLCm12jKsxFGZmVSlzfGVehzIuwYCfjt5BtrX1eB2KySCWJDLAS7ucUqWnZdH5EbEKC4RlVrxmmFOu1Jd1CT843CIMexqHySyWJDLAms2ZXao0GVa8xtHZO8CW1u6MXh48niNnVVFWXGDjEuYQKU8SIlIoIs+LyKOjbDtbRNpFpMG93Byz7RMiskFE1ovIAyKSXW33cVjd3MrC2swtVZqMaPGal3d1eh2Kp17Y3o5q9o1HABQVFrB8ns9aEuYQ6WhJ3AhsHGP7U6q6wr3cAiAi84CPAStVdRlQCFye+lDTr3/QLVWaBUuDjyVazjTfT6qLDt7XZ9EJkbGCAT/rd3QwMJTfLUJzUEqThIgEgAuBOydw9yKgXESKgApgx1TGlikaQ9FSpdmdJALTyplRWZL3y3M0hcIcPr2CaZUlXocyIcE6P/2D1iI0B6W6JXEr8GlgrMOSU0WkUUQeF5FjAVR1O/AN4DVgJ9Cuqn9McayeWN3cSoHAqQuzdzwCnOI19QHfcKGdfNXYEs7Krqaog2dehz2Nw2SOlCUJEbkI2KOqz46x23PAfFUNAt8Ffu3edxpwCXAEMBeoFJEr4zzP9SKyTkTW7d27dypfQlqsbm5lWRaUKk1GfcDPK3s66e4b9DoUT+zp7GVHe29WnUQ3UmBaOdMqim1cwgxLZUvidOBiEdkGPAicIyL3x+6gqh2q2uX+/hhQLCIzgTcBW1V1r6oOAI8Ap432JKp6h6quVNWVtbW1KXw5Uy9aqjTbu5qiVtT5iSisz9PiNdH1q7K5JSEiTo0QOzHSuFKWJFT1c6oaUNUFOIPOf1XVQ1oDIjJb3MnkInKSG08bTjfTKSJS4W4/l7EHv7PS2q1OqdJsH7SOig5e52uXU1MoTIHAsXMzu1xpIsE8bxGaQ6X9PAkRuUFEbnCvXgasF5FG4DvA5ep4BngYpzvqBTfOO9Ida6qtbs6eUqXJmFFVyjx/ed72ZzeE2llyWDUVJUVehzIp+d4iNIdKy6dZVZ8EnnR/vz3m9tuA2+Lc54vAF9MQnmeyrVRpMoJ1vrxMEqpKUyjMm4+Z7XUokxZtETaGwpyc5RMqzOTZGdceac3CUqXJCAb8tOw7wL7ufq9DSavX9vUQ7hnI6vGIqBlVpQSmldu4hAEsSXjmabdUaa4lieFypnnWmogW66nP4plNsYJ1fhpshpPBkoRnVjdnX6nSZCwP+BDJv2XDG1vClBYVcNTsaq9DmRIrAn62hw/Q2tXndSjGY5YkPLJ6s1OqtDBLylsmq6q0iMW1VXnXkmgKhTl2bg3FWVR6diwHZ6qFvQ3EeC43PtFZ5rU2p1TpGTnW1RRVH/DTGGrPm+I1g0MR1m/PrnKliSyb56NAoCHPWoTm9SxJeGB1DiwNPpZgnY/Wrj52tPd6HUpavLKniwMDQwSzcHnweCpLi5xypjYukfcsSXhgdXMrh9VkZ6nSZES/LPNlsb9ol0yuDFpHBQN+mkJWzjTfWZJIs2ip0tMXZWep0mQsnVNNcaEMz/jJdQ0t7dSUFbFgRqXXoUyp+jof+3sGaNl3wOtQjIeSShIiskRE/iIi693r9SLyhdSGlpuyvVRpMkqLCjl6Tk3edFU0hcLUB/wU5NgkhGiLMN9rhOS7uEnCXT5jqXv1R8DngAEAVW0iR4sApVoulCpNRjDgZ/32diKR3O6q6B0Y4qVdnQTrcqurCeCo2dWUFhXkTbI3oxurJXE/TmIAqFDVtSO22+pfE7AqB0qVJqM+4KOzb5Atrd1eh5JSG3Z0MBTRrKxpnUhxYQHL5vlsGmyei5sk3CW8r3OvtorIIkABROQynGJAZhz6ByOs3bovZ6e+xopOB831o9Do61uRQ9NfY9UHfLywvZ1BK2eat8Yck3BrOQB8GPghsFREtgMfB26Idz8zumip0tNyZGnwsSyqraKypDDnj0KbQmEOqynlsJoyr0NJiRV1fnoHImza3eV1KMYjCVeBFZFC4IOq+iYRqQQKVNUK4E7Aqldyo1RpMgoLhGXzfDk/w6kx1J5T50eMFH1tjaEwx2R5nQwzMQlnN6nqEHCC+3u3JYiJW7O5leU5Uqo0GcE6Py/u7KB/MDe7Ktp7Btja2p1TZ1qPNH9GBb7y4pxvEZr4kj1P4nkR+a2IXCUib49eUhpZjomWKs3lqa8j1Qd89A9GeHlXbh5XNG0PA+R0S0JEqA/4bHmOPJZskpiOU1b0HOCt7uWiVAWVi3KtVGkyYrsqclG0TOvyHDvTeqQVdX427e6kp98mNOajpCrTqeo1qQ4k1+VaqdJkBKaVM72yxO2qmO91OFOusSXMETMr8ZXndvdhMOBnKKJs2NHBiQumex2OSTM74zpNVjW35lyp0kSiXRW5WluiMRQmmOOtCHCW54Dcn85sRmdnXKdBa1cfL+3qzLkqdMkIBvy8sif3uip2tfeyu6MvJ0+iG2lWdRnz/OU5P1PNjM7OuE6DXC1VmoxgnY+IwvrtHV6HMqWi4yy5PLMpltMiDHsdhvGAnXGdBrlaqjQZ0SPtXPuCaQqFKSoQjs2TcweCdX5e29fDvu5+r0MxaTaZM64/mNrQcsfqza2cmoOlSpMxs6rU7aoIex3KlGpsaeeo2dV5M8aU6zPVTHxJDVyr6hZVfRNQCyxV1TNUdVtKI8sR0VKl+djVFBWs8w1PF80FkYgOLw+eL5YHfIhAU45OQjDxJTUFVkRKgXcAC4CiaLEcVb0lZZHliIOlSvM3SdQH/Dz2wi72dfczvbLE63AmbVtbNx29g6zIweXB46kqLWJxbZW1JPJQsifT/Qa4BGewujvmYhI4WKo0t6qWjcdwOdMc+YKJtoryqSUBzrhEY4uVM803SbUkgICqviWlkeSgSERZs7mNs5fU5myp0mQMd1WE2jn7qFlehzNpDS1hyosLOXJWbtYojydY5+fhZ0OE9h+gbnqF1+GYNEm2JbFGRJanNJIc9NKuTvZ19+d1VxM4XRWLaqtyZoZTUyjMsnk1FBXmV4n4FcMtQhuXyCfJfsrPAJ4VkZdFpElEXhCRplQGlgtWN9t4RFR9wFk2PNu7KgaGImzY0ZHTi/rFc9TsakoKC2xcIs8k2910fkqjyFGrNzulSmf7crMgzXisqPPzyHPb2dney1x/9pZufXlXJ32DEerz5CS6WCVFBRwzt4aGHGkRmuQkOwX2VaAOOMf9vSfZ++arfCpVmoxcOaku2tWSD2s2jWZFnZ/129sZimR3i9Akb6y1m46N+f2LwGc4uExHMc6yHSaOhpb8KVWajKPnVFNcKFm//k9jSxh/RTGH5+nAbbDOR0//EM17rJxpvhirNTBfRL7m/v424GLcaa+qugOoTnFsWW11c/6UKk1GaVEhR8+pyfppsI3uSXT5OlstV1qEJnljrd30GPCEe7VfnRHH6NpN+TvpP0mrm/OrVGky6gM+Xgi1E8nSroqe/kE27e5kRZ52NQEcMaOS6rIiGrI82ZvkJVq76Q/urw+JyA8Bv4j8K/BnnOXDExKRQhF5XkQeHWXb2SLSLiIN7uVm9/ajYm5rEJEOEfn4uF6Zh7r7Bmloya9SpcmoD/jp7BtkS2t2noe5YUcHEc2/k+hiFRQIwYDfWhJ5JNnKdN8QkfOADuAo4GZV/VOSz3EjsBGIt1zmU6p6SClUVX0ZWAFOkgG2A79K8vk8Fy1VaoPWh1rhzghqCoVZnIUnokW/GOvzaDmO0QTrfPzwb1voHRjKmwUO81nSM5RU9U+q+ilV/WSyCUJEAsCFwJ0TDRA4F9jszqrKCqvcUqUnzM+fUqXJWFRbRUVJYdaejNUYameur4xZ1fk9pbk+4GfQLWdqcl+y5Us73S6f2EuLiPxKRBaOcddbgU8DkTH2OVVEGkXk8dgZVTEuBx4YI7brRWSdiKzbu3dvMi8n5VY3t3LigvwqVZqMwgJh2Txf1s6zb2wJ502RobFEW4TW5ZQfkm1JfAv4FDAPCACfxBmTeBD48Wh3EJGLgD2q+uwYj/scMF9Vg8B3gV+PeIwSnFlVv4j3AKp6h6quVNWVtbW1Sb6c1ImWKrWpr6NbUefnxZ0d9A+OddyQefZ39/Pavp68Ho+IOqymjNk1ZXbmdZ5INkm8RVV/qKqdqtqhqncAF6jqz4F4fSqnAxeLyDacZHKOiBxyboX7WF3u748BxSIS++16PvCcqu4ex2vy1Jo8LlWajPqAj/7BCJt2d3odyrgcLFea3+MRUblWI8TEl2ySiIjIu0SkwL28K2bbqPMZVfVzqhpQ1QU4XUZ/VdUrY/cRkdniTjgXkZPceNpidrmCMbqaMtGaPC5VmozomkfZ1uXUFGpHBPu7uuoDfra2dhPusXKmuS7ZJPFe4CpgD7Db/f1KESkHPjKeJxSRG0TkBvfqZcB6EWkEvgNc7p6PgYhUAOcBj4zn8b22qjl/S5UmIzCtnOmVJVl3Ul1jS5hFtVVUl9l5LxA7U81aE7ku2SmwW4C3xtm8Kon7Pwk86f5+e8zttwG3xblPD5BVpyu/1tZDaP8Brj9rrLH8/CYi1Aeyq6tCVWkMtXPWEutCjFrunlDY2BLmrCXejwWa1LFF+qZQtFSpDVqPrT7gZ9PuTnr6B70OJSk723tp7erLy+XB46kpK2ZRbWXWr8VlErMkMYVWWanSpAQDPiIK67dnxzz76FRPm/56qGDAT4OVM815liSmSCSiPL25jdMXz8zbxd+SVZ9lNa8bQ+0UFwpHz7E1LWMF6/y0dvWxs73X61BMCiV7Mt2NIlIjjrtE5DkR+ZdUB5dNNu7qcEqVWldTQrXVpczzl2fNDKfGljBHz6mhtMhOjowVtJPq8kKyLYkPqGoH8C9ALXAN8LWx75Jf1jTb+RHjkS2D15GI8sL2durzeOXXeHKlRogZW7JJItp/cgFwt6o2xtxmcAatF1mp0qQF6/y8tq+H/d2ZPc9+S2sXXX2DNmg9itKiQo6ZU2MtiRyXbJJ4VkT+iJMk/iAi1Yy9HlNe6R+M8MyWfdaKGIfokXnT9sw+Cm1sccuV2qD1qOoDfl6wcqY5LdkkcS3wWeBE9/yFEpwuJ4Nz9vCBgSFLEuOwfJ4Pkczvz24MhaksKWRRbfYtbZ4OwTo/XX2DbNlr5UxzVbJJQoFjgI+51ysB61dxRUuVnmKlSpNWXVbMotqqjJ/h1BhqZ9k8n51BH8cKdy2rbJmEYMYv2STxfeBUnLWUADqB76Ukoiw0XKq03JZsGI/6gI+GlvaMnWffPxhh446O4SUozOstnFlFVWlRVkxCMBOTbJI4WVU/DPQCqOp+nC6nvNflliq1rqbxCwYye579S7s66B+K2PLgYygoEJbP89my4Tks2SQx4JYRjS6+V4sNXAOwdmsbgxG1JDEBwZhypplouFypTX8dU7DOz8adHfQODHkdikmBZJPEd3BqTM8Ska/iLOr3XymLKousbm6j1EqVTkimz7NvDLUzo7KEwLRyr0PJaCvqfAwMKRt3ZscyK2Z8Eq4CKyIFwFacMqTn4pwfcamqbkxxbFlhdXMrK61U6YSUFhWydHbmzrNvCoWpD/hsmZUEgjHLhh93uB0s5ZqELQlVjQDfVNWXVPV7qnqbJQiHlSqdvGCdjxdC7UQybJ59V98gr+zpsvMjkjC7poza6tKMTfZmcpLtbvqjiLxD7JDqENFSpWfYeMSE1Qf8dPYNsrWt2+tQDrF+ezuq2JnWSRARZ0XYDB1bMpOTbJK4CfgF0CciHSLSKSJ53wG5+pVWasqKWGYlLScs+iWcaUehNmg9PivqfGzZ2037gQGvQzFTLKkkoarVqlqgqiWqWuNer0l1cJlu9eZWTrFSpZOyeFYVFSWFGTfPvinUTmBaOTOqSr0OJStEu+XWZ/gyK2b8xkwSIrLU/Xn8aJf0hJiZoqVKzzjSupomo7BAWJaB8+wbWsI2HjEO9fP8gJ15nYsSzW66Cbge+OYo2xQ4Z8ojyhKrmq1U6VQJBnzc+/Sr9A9GKCnyvg5Wa1cf28MHuPq0+V6HkjV8FcUcMbMy47oNzeSNmSRU9Xr35xvTE072WL25ldk1ZVaqdArUB/z0D25l0+7OjBjfiZ7cZ4PW4xMM+Hh6S5vXYZgplvRhm4gsE5F3icj7opdUBpbJoqVKT1s8w+bQT4Ho2kiZ0uXU2NJOgZARCSubBOv87O7oY1eGLrNiJibZ8qVfBL7rXt4IfB24OIVxZTQrVTq1AtPKmVZRnDFdFY2hMEfOqqayNOG5piZGdI2rTEn2Zmok25K4DOds612qeg0QBPJ22oeVKp1aIkJ9wJ8RM5xUlaaQlSudiGPn1lBUIBmT7M3USDZJHHDPvB4UkRpgD7AwdWFltlXNVqp0qgXr/Gza3UlP/6CncYT2H2Bfdz/1NrNp3MqKC1k6p9paEjkm2SSxTkT8wI+AZ4HngLWpCiqT9Q9GWLt1n51lPcWCAR8RhQ07vD1HM/oFt8IGrSck6LYIM22ZFTNxic6TON399ROqGlbV24HzgKvdbqe8Ey1VepoliSlVnyFnXjeF2ikpLOCo2dWexpGtggE/nb2Zt8yKmbhELYnvuD+fjt6gqttUtSl1IWW2VVaqNCVqq0uZ5y/3fNnwhpYwx8ytyYjzNbJR9AREr5O9mTqJpm8MiMjdQEBEvjNyo6p+bJT75LQ1za0sD/itVGkK1Ad8nhYgGooo67e3884TAp7FkO2iy6w0toR5+/H2PuaCRIdLFwF/AA7gjEWMvOSV4VKli6wVkQr1AT+vtvWwv7vfk+dv3tNFT/+QLccxCYXD5Uy9n6lmpkailsSnVPUzInK4qt6blogymJUqTa2gO+20aXs7b1hSm/bnjw5aW03ryQnW+bln9baMWWbFTE6iv+AFIlIMXJ6OYDKdlSpNrWUBHyLQ5FF/dmNLmOrSIhbOtKVWJiMY8NM/FOGlXXlfTSAnJEoSvwdagXq3jkRHPteTsFKlqVVTVszCmZWezbNvCrWzPOCjwJZ+n5RgndMitMHr3DBmklDVT6mqD/idW0eiZrz1JESkUESeF5FHR9l2toi0i0iDe7k5ZptfRB4WkZdEZKOInDruVzeFoqVKrasptYIBP42hdlTTO8++d2CIjTs7bDxiCszzlzOzqsTGJXJEskWHLpnEc9wIjFUT+ylVXeFebom5/dvA71V1Kc4yIJ7W1Y6WKrX1mlIrWOdnb2cfuzrSu0jcxp0dDEZ0eFzETFy0nKm1JHJDsgv8nSIi/xSRLhHpF5GhZLqbRCQAXAjcOZ6g3KU/zgLuAlDVflUNj+cxppqVKk2P6JpJ6f6CiT6ftSSmRn3AT/PeLjp7rZxptkt26sFtwBXAK0A5cB3OirCJ3Ap8GoiMsc+pItIoIo+LyLHubQuBvcDdblfVnSIy6miiiFwvIutEZN3evXuTfDnjo6qsam7l1EVWqjTVjp7jLhKX5q6KplA7tdWlzK6x9bimQrDOhyq8YOVMs17S89NUtRkoVNUhVb0bZ8nwuETkImCPqo51PsVzwHxVDeIknV+7txcBxwM/UNXjgG7gs3HiukNVV6rqytra1EybfG1fD9vDB2w8Ig3Kigs5ek5N2k+qawyFCQZ8Vh9kikQLNmXCyr5mcpJNEj0iUgI0iMjXReQTQKJ5gqcDF4vINuBB4BwRuT92B1XtUNUu9/fHgGIRmQmEgJCqPuPu+jBO0vDEalsaPK3qAz6aWtK3SFxH7wCb93ZbJbopNK2yhPkzKmxcIgckmySucvf9CM5RfR3wjrHuoKqfU9WAqi7AOc/ir6p6Zew+IjJb3EM3ETnJfY42Vd0FtIjIUe6u5wIvJhnrlIuWKrX58+kRDPjp7EvfInHr3aNdWx58atXb4HVOSKr0lqq+6v7aC3x5Mk8oIje4j3k7TjGjD4rIIM7SH5frwbmPHwV+6rZgtgCerDobiShrmlt549JZ1hWRJtHB46ZQmEW1VSl/vobhmtY2KWEqBQM+/rdxB3s6e5lVbWM92WrMJCEiTwAK7FPVyyb6JKr6JPCk+/vtMbffhjMoPtp9GoCVE33OqbJxVwf7ewasfkQaHVwkrp23HZf6ReKaWtqZP6MCf0VJyp8rn0Rrlze1tPOmYyxJZKtELYn3uz+HUhxHxlrd3ArYeEQ6FRYIy+b60nbmdWMozIkLpqflufLJsXN9FBYIjaEwbzrmMK/DMROU6IzrV91LKF0BZZrVzW0snlXFYTY1Mq2CdT5e3NHBwNBYs6cnb09HLzvbe62mdQqUlxSy5LBqGmxcIqslqkzXOWLNpkMu6QrSK9FSpbY0ePrVB/z0DUZ4eVdnSp8nej7GChu0TokVdT4aW8JpX2bFTJ1ELYnoGk234pynMA8IAJ8BvpLy6Dz2/Gv7rVSpR6LTUVPd5dQUClNYIBw711oSqRAM+OnoHWRbW4/XoZgJSnYK7JtV9fuq2ume2/ADEkyBzQWrN7dZqVKP1E0vZ1pFMU0tqT0Zq6ElzJLDqikvsZV9UyF2pprJTskmiSERea+7omuBiLyXPBjMtlKl3hERZ559Cr9cVJWmULtNfU2hI2dVUVZcYOMSWSzZJPEe4F3AbvfyTve2nGWlSr0XDPjYtLuTnv7BlDz+q209tB8YsEp0KVRUWOCUM7UkkbWSXSp8m6peoqozVbVWVS9V1W0pjs1T0VKldn6Ed+oDfiIKG3akZo5EtJUSLZJjUiMY8LMhDTPVTGpYAdo4Vr3ilCo93kqVeqY+xRXOmkLtlBYVsOSw6pQ8vnEE69IzU82khiWJONZsbuXEBdOtVKmHZlWXMddXlrJlwxtbwiyb56O40P4NUildM9VMath/xyj2djqlSk9bbOMRXqsP+FMyM2ZwKML6He12El0aRGeq2bhEdkq2Mt1hInKXiDzuXj9GRK5NbWjeWbPZXYrDSpV6Lljn59W2HsI9/VP6uJt2d9E7ELGT6NJARAjW+WlM8XRmkxrJtiTuAf4AzHWvbwI+noJ4MsKa5jYrVZohotNTp7rLKdo6sZlN6REM+HllTyfdfamZqWZSJ9kkMVNVH8ItQ6qqg+ToeRJWqjSzLHOTRNMUd1U0hsLUlBWxYEbFlD6uGV2wzkdEYb2VM806ySaJbhGZgbNsOCJyCpCTf+1oqVKb+poZasqKWVRbOeUticaWdoJ1fqsRkib1NnidtZJNEjcBvwUWichq4Cc4RYFyTrRUqa3XlDmC7pnXU7VI3IH+IV7e3WnlStNoZlUpgWnlNi6RhRImCREpBN7gXk4D/g04VlWbUhybJ1Y3W6nSTFMf8LG3s49dHb1T8ngv7mxnKKI2synNgnWpXWbFpEbCJKGqQ8AlqjqoqhtUdb2qDqQhtrSLRJQ1m1s5ffFM64bIINFF4qbqKLShxZYH98KKgJ/Q/gO0dvV5HYoZh2S7m1aLyG0icqaIHB+9pDQyD0RLlZ5u50dklKPn1FBUIFN2vkRTKMzsmjJmWSGptIq23GxF2OySqHxp1Gnuz1tiblPgnKkNx1tWqjQzlRUXsnRO9ZR1VTS2hK2ryQPL5vkoEKcld85SK2eaLcZMEiJyo6p+G/gPVV2Vppg8Y6VKM1d9wM//Nu4gElEKJjE1ub1ngG1tPbxzZd0URmeSUVlaxJLDqq0lkWUSdTdd4/78TqoD8ZqVKs1sKwJ+OnsH2dbWPanHadoeBrCZTR4JBvxWzjTLJEoSG0VkG7BURJpiLi+ISE7NboqWKrWupsw0vCLsJI9Co+sHLbfuJk/U1/nY3zNAy74DXodikjRmd5OqXiEis3GW5Lg4PSF5I1qq9GQrVZqRFtdWUV5cSGNLO287LjDhx2kMtbNwZqVVG/RItAXXEApzuJ3tnhXGbEmIyF9UdRfwB1V9deQlTTGmxWorVZrRohXOJtuf3dgSHp5Sa9LvqNnVlBYVTPkyKyZ1EnU3zRGRNwBvFZHjYqe/5tIU2M7eARpawpxhU18zWn3AN6kKZ7vae9nT2WczmzxUXFjAsnk+O6kuiySaAnsz8FkgAHxrxLacmQK7dus+hiJqS4NnuPo6P32rtvLyrs4JrdDb4B69WkvCW/UBHw+sfY3BoQhFVvAp4435F1LVh1X1fODrqvrGEZecSBAAW1u7qSwptFKlGW6F25/dNMHF/ppCYYoKhGPm1ExhVGa8VtT56R2IsGl3l9ehmCQkGpNY6v76u5FdTbnU3XTdmQtZ94XzrFRphptshbPGUJilc6rt7+yx4HCyD3sah0lOou6mm4DrgW+Osi1nupsAykvsiyPTiQjLAxNbJC4SUZpC7bw1ODfxzial5s+owFdeTGMozOUnHe51OCaBRFNgr3d/vjE94RgzthUBH997spWe/kEqSpJdVQa2tnXT2Ts4XOnOeEdEqA/4hhdaNJkt6VEjETlNRN4jIu+LXlIZmDGjqQ/4GYooG3Z0jOt+0a4NG7TODCvq/Gza3cmB/pwscJlTkkoSInIf8A3gDOBE97IyhXEZM6rhM6/HOS7R2NJOeXEhi2urUhCVGa/gcLK31kSmS7a9vhI4Riew4IpbtGgdsF1VLxqx7WzgN8BW96ZHVPUWd9s2oBOnlvagqlpSMsyqLmOOr2zcM5waQ2GWz/PZlMsMEU32DS1hVi6Y7nE0ZizJJon1wGxg5wSe40ZgIxBv3uFTI5NHjDeqausEntPksGDAP66ZMQNDETbs6OB9p8xPXVBmXGZVlzHXVzbltcvN1Eu0VPj/4sxiqgZeFJG1wHBZKVUdcz0nEQkAFwJfxZkpZcyk1df5+P2GXYR7+vFXlCTc/+VdnfQPRmw8IsME6/wTns5s0idRS+Ibk3z8W4FP4ySZeE4VkUZgB/BJVd3g3q7AH0VEgR+q6h2j3VlErseZpsvhh9t0unwQjDmp7qwltQn3j06ZteXBM0uwzs/j63exv7ufaZWJk73xRqIO2u044wF/i73gfIGHxrqjiFwE7FHVZ8fY7TlgvqoGge8Cv47ZdrqqHg+cD3xYRM4a7QFU9Q5VXamqK2trE39hmOy3fJxlMBtbwkyrKKZuenkKozLjFU3ato5TZkuUJG7FGTweqcfdNpbTgYvdAegHgXNE5P7YHVS1Q1W73N8fA4pFZKZ7fYf7cw/wK+CkBM9n8kRNWTELayuTnmffFGqnPuBHZOIV7czUWx7wIeLMPMsGj72wk7P/3xP8pmG716GkVaIksUBVX1dcSFXXAQvGuqOqfk5VA6q6ALgc+KuqXhm7j4jMFvc/V0ROcuNpE5FKEal2b68E/gVn8NwYIPnB657+QTbt7rTxiAxUVVrE4tqqjG9J9PQP8tlfNvGhnz7Hns4+bnqokb9s3O11WGmTKEmMVex5Qm13EblBRG5wr14GrHfHJL4DXO5Osz0MWOXevhb4nar+fiLPZ3JTMOBjT2cfu9p7x9xv/fYOIoqdaZ2hooPXmVrOdMOOdt763VX8fF0LHzx7EWs+ew7L5tbwoZ8+xzNb2rwOLy0SJYl/isi/jrxRRK4FxhprOISqPhmd5qqqt6vq7e7vt6nqsaoaVNVTVHWNe/sW97agu/2ryb8kkw/q3ZZBQ4LZMdHZM/U2aJ2RgnV+2rr72R7OrHKmqspdq7bytu+tobN3kJ9eezKfectS/BUl3H3NSQSmlXPdvetYvz07usomI1GS+DhwjYg8KSLfdC9/A67DOf/BGE8cM6eGogJJ2OXUGAozz19ObXVpegIz4xJt4WXSuERrVx8fuOef/OejL3LWkpn8/uNncdrig7VmpleWcN+1J1NdVsT7717L1tZuD6NNvUT1JHar6mnAl4Ft7uXLqnqqW9bUGE+UFReydE51wjOvG0Nhq0SXwZbOrqGksCBjxiX+vmkvb7n1KVZvbuOWS47lR+9byfRRpufO9Zdz33UnowpX3vlMwm7PbJbUGgWq+oSqfte9/DXVQRmTjHp32fBIZPT+7H3d/bTsO2CD1hmspKiAY+bWJOw2TLX+wQj/9dhG3vfjtUyvLOa3Hzmd9526YMwZcYtqq7j3AyfRfmCAq+56hv3d/WmMOH1sIRuTtYIBH529g2xrG725Hz06tZZEZltR52f99naG4iT7VNuyt4t3/GANd/x9C1eecji//cgZLJ2dXPXCZfN83Hn1Sl7d18M19/yT7r7BFEebfpYkTNaKthDidTk1tbQjAssnUA/bpE+wzkdP/xDNe9JbzlRV+cW6Fi767ipa9vfww6tO4CuXLh935cJTFs7ge+85nhe2t/Nv9z1L32BuLX9uScJkrcW1VZQXF8btqmgKhVlUW0V1WXF6AzPjEp15ls51nDp6B/jYgw186uEm6gM+Hr/xTN587OwJP955xxzG199Rz6rmVj7x8wbPWkWpkHxpL2MyTFFhAcvm1Yw6w0lVaQyFecOSWekPzIzLETMqqS4roiEU5l0n1qX8+Z59dT83Pvg8O9t7+dSbj+KGNyyisGDyZ+O/44QA4QMD/OejL1JT9gL//fblOXGWvyUJk9XqA37u/8erDAxFKI6pFbGjvZfWrn6CddbVlOkKCmTcy79PxFBE+f4Tzdz6l1eY6y/jFzecyvGHT5vS57j2jCMI9/Tz3b82468o4bPnL53Sx/eCdTeZrBas89M3GOHlXYcuMRbturCVX7NDsM7HSzs76R1ITX/+zvYDvOdH/+Cbf9rEhcvn8LuPnTnlCSLqpvOWcOUph3P73zbzw79tTslzpJO1JExWCw6vCNvOspgB6sZQmOJCYemcsVapN5miPuBn0K1dfsL8qf3y/v36XXzml00MDEX4xjuDvOP4eSntBhIRvnzxMsI9A/z34y/hryjm3SdmbxkDa0mYrHb49Ar8FcWv66pobAlzzJwaSovGN1PFeGOFO1NtKgevD/QP8X9+9QI33P8sh0+v4HcfO5PLTgikZZygsED41rtW8IYltXzukRf4/fqJFPXMDJYkTFYTEfekuoPTYIciyvrtHbZeUxY5rKaM2TVlUzYu8dKuDi6+bRU/feY1/u2shfzyg6dxxMzKKXnsZJUUFfCDK4/nuMOn8bEHGljdnJ2VmC1JmKwXDPjYtLuTA/1Of/aWvV109Q3amdZZJljnm3TNa1Xl3jXbuPi21YQPDHDftSfxuQuOpqTIm6+6ipIifnz1iSysreT6n6zLynKtliRM1qsP+BmKKBt2OF8w0S8aWx48u9QH/Gxt7SbcM7HlLdq6+rju3nV88bcbOGPxTH5/45mceaT31Sp9FcX85AMnMaOqlPffvZbmPaPVcctcliRM1hteSdRNDo0tYSpLCllYW+VlWGacViQ4g34sq5tbOf/bT/HUK6188a3HcNfVK5lRlTkr/86qKeP+a0+mqLCAK+9cS2h/j9chJc2ShMl6s2rKmOMrG27KN4XCLA/4puQEKZM+461dDjAwFOFrj7/ElXc9Q3VZEb/+8Olcc/oRGXkS2+EzKrjv2pPo6R/kqrvW0trV53VISbEkYXJCfcBHUyhM3+AQL+7ssPMjslBNWTGLxlG7/NW2bi77wRpu/9tmLj/xcB796JkcMze5hfm8snR2DXdfcyI72w9w9Y/X0tE74HVICVmSMDkhWOdnW1sPz2zZx8CQ2qB1lgoG/DQkUc70kedCXPDtp9ja2s0P3ns8//325ZSXZMd05xPmT+f2K0/g5V2dXHfvupSdQDhVLEmYnBBtOdz3j1cBWx48WwXr/LR29bEzThGfzt4BPv7g89z0UCPHzvXx+MfP4vzlc9Ic5eSdfdQsvvXuFfxz2z4+8rPnGBiKeB1SXJYkTE6Inm39l427mVlVwjx/uccRmYk4uPx7+HXbnn9tPxd+ZxX/27STm85bwgPXn5LVf+eLg3O55ZJl/HnjHj7zcFPc4llesyRhcoKvvJiFtZVE1JlKmYkDlyaxo+dUU1woh4xLRCLK959s5p23P81QRHno307hY+cemRMTE646ZT7/ft4SHnl+O//5uxcTdrN5wdZuMjkjGPCzZW+3DVpnsdKiQo6eUzM8U213Ry+f+HkDaza3cVH9HL76tuX4ynOrPshHzlnM/p4Bfrx6K9MrSvjouUd6HdIhLEmYnFEf8PGr57dTb8uDZ7VgwM+vnt/OHzbs4rO/bKJ3IMLX31HPO1emZ92ldBMRvnDh0bQfGOCbf9qEv7KEq06Z73VYwyxJmJzx1uBcWvYd4NSFM7wOxUxCsM7Pff94lX+771mOnVvDd644jkU5fmJkQYHwf9+xnPYDA9z8m/XUlBVxyYp5XocF2JiEySEzq0q5+a3HjLtGsckspy6awbSKYq474wge+dBpOZ8goooKC7jtPcdx0oLp/PtDjTzx8h6vQwJAMnGgZKJWrlyp69at8zoMY8wkqWpOdi0lo7N3gCt+9A+a93Rx/7Uns3LB9JQ/p4g8q6orR9tmLQljTMbJ1wQBUF1WzD3XnMRcXzkfuOefbNzZ4Wk8liSMMSbDzKwq5SfXnkRlaRFX3bWWV9u6PYvFkoQxxmSgwDRnQcChSIQr73qG3R2jn4WeapYkjDEmQy2eVc0915zEvq5+3nfX2gnX2pgMSxLGGJPBgnV+7njfSra2dvOBe/5JT/9gWp/fkoQxxmS40xfP5DtXHEdDS5gb7n+O/sH0LQhoScIYY7LAW5bN5mtvr+fvm/Zy00MNDKVpQcCUJwkRKRSR50Xk0VG2nS0i7SLS4F5uTva+xhiTb951Yh2fv2Apjzbt5ObfrE/LgoDpWJbjRmAjEK9k1FOqetEE72uMMXnl+rMWsb9ngB88uZlpFSV88s1HpfT5UtqSEJEAcCFwZzrva4wxuezTbz6KK06q47YnmrnzqS0pfa5UdzfdCnwaGGuU5VQRaRSRx0Xk2HHeFxG5XkTWici6vXv3TjZeY4zJeCLCVy5dzgXLZ/OV323k4WdDKXuulCUJEbkI2KOqz46x23PAfFUNAt8Ffj2O+wKgqneo6kpVXVlbWzsFkRtjTOYrLBD+590rOPPImXzml038ccOulDxPKlsSpwMXi8g24EHgHBG5P3YHVe1Q1S7398eAYhGZmcx9jTEm35UWFXL7lSfwhiW1HFZTlpLnSMsqsCJyNvDJkQPUIjIb2K2qKiInAQ/jtCw00X1HY6vAGmPM+I21Cmzaiw6JyA0Aqno7cBnwQREZBA4Al2surV1ujDFZzupJGGNMnrN6EsYYYybEkoQxxpi4LEkYY4yJy5KEMcaYuCxJGGOMicuShDHGmLhyagqsiOwFXp3g3WcCrVMYzlSxuMbH4hq/TI3N4hqfycQ1X1VHXdcop5LEZIjIunjzhL1kcY2PxTV+mRqbxTU+qYrLupuMMcbEZUnCGGNMXJYkDrrD6wDisLjGx+Iav0yNzeIan5TEZWMSxhhj4rKWhDHGmLgsSRhjjInLkgQgIm8RkZdFpFlEPut1PAAi8mMR2SMi672OJZaI1InIEyKyUUQ2iMiNXscEICJlIrLWrZe+QUS+7HVMsUSkUESeF5FHvY4lSkS2icgLItIgIhmzxr6I+EXkYRF5yf2cnZoBMR3lvk/RS4eIfNzruABE5BPuZ369iDwgIlNaoi7vxyREpBDYBJwHhIB/Aleo6osex3UW0AX8RFWXeRlLLBGZA8xR1edEpBp4Frg0A94vASpVtUtEioFVwI2q+g8v44oSkZuAlUBNMlUW08EtD7xSVTPqxDARuRd4SlXvFJESoEJVwx6HNcz9ztgOnKyqEz15d6pimYfzWT9GVQ+IyEPAY6p6z1Q9h7Uk4CSgWVW3qGo/Tk3tSzyOCVX9O7DP6zhGUtWdqvqc+3snsBGY521UoI4u92qxe8mIIyARCQAXAnd6HUumE5Ea4CzgLgBV7c+kBOE6F9jsdYKIUQSUi0gRUAHsmMoHtyThfMG1xFwPkQFfetlARBYAxwHPeBwKMNyl0wDsAf6kqhkRF3Ar8Gkg4nEcIynwRxF5VkSu9zoY10JgL3C32z13p4hUeh3UCJcDD3gdBICqbge+AbwG7ATaVfWPU/kcliRARrktI45AM5mIVAG/BD6uqh1exwOgqkOqugIIACeJiOfddCJyEbBHVZ/1OpZRnK6qxwPnAx92uzi9VgQcD/xAVY8DuoGMGCcEcLu/LgZ+4XUsACIyDafn4whgLlApIldO5XNYknBaDnUx1wNMcXMt17h9/r8Efqqqj3gdz0hu98STwFu8jQSA04GL3f7/B4FzROR+b0NyqOoO9+ce4Fc4Xa9eCwGhmFbgwzhJI1OcDzynqru9DsT1JmCrqu5V1QHgEeC0qXwCSxLOQPWRInKEe5RwOfBbj2PKWO4A8V3ARlX9ltfxRIlIrYj43d/Lcf55XvI0KEBVP6eqAVVdgPPZ+quqTumR3kSISKU78QC3O+dfAM9n0qnqLqBFRI5ybzoX8HRSxAhXkCFdTa7XgFNEpML93zwXZ5xwyhRN5YNlI1UdFJGPAH8ACoEfq+oGj8NCRB4AzgZmikgI+KKq3uVtVIBzZHwV8ILb/w/weVV9zLuQAJgD3OvOPCkAHlLVjJlumoEOA37lfK9QBPxMVX/vbUjDPgr81D1o2wJc43E8AIhIBc4syH/zOpYoVX1GRB4GngMGgeeZ4uU58n4KrDHGmPisu8kYY0xcliSMMcbEZUnCGGNMXJYkjDHGxGVJwpg0EpElIuL5si/GJMuShDFxiIiKyH0x14tEZO94V3J1V1udCaCqm4AVIvK2ePsYk0ny/jwJY8bQDSwTkXJVPYAzR377ZB9UVTNqGXNjxmItCWPG9jjOCq4w4mxbEZkuIr8WkSYR+YeI1Lu3zxCRP7oL1P2QmPXBROTKmLoXP3RP/jtEzD4N0X3cyz1uzYAXROQTqX3ZxjgsSRgztgeBy91CLvUcuuLtl4HnVbUe+DzwE/f2LwKr3AXqfgscDiAiR+MszXG6qgbdfQ9ZosPd593uPiuAIeC9wApgnqouU9XlwN1T/DqNGZV1NxkzBlVtcpdEvwIYufTIGcA73P3+6rYgfDj1EN7u3v47Ednv7n8ucDTwJ3c5jCoOXaY+us8JwD/dfcpxlj7/X2ChiHwX+B0wpctBGxOPJQljEvstzpr9ZwMzYm4fa5n50da7EeAXqjrW0tcC3Kuqn3vdBpEg8Gbgw8C7gA8kjNyYSbLuJmMS+zFwi6q+MOL2v+N0BSEiZwOtbm2N2NvPB6a5+/8FeIeIzHK3zXBbKbH+AlwWs890EZnvznwqUNVfAv9BZi2fbXKYtSSMSUBVQ8C3R9n0JZwKak1AD3C1e/uXgQdE5DngbzjLOaOqL4rIF3CqwRUAAzitgm0xzxVvnwPuc0UP7F7X0jAmFWwVWGOMMXFZd5Mxxpi4LEkYY4yJy5KEMcaYuCxJGGOMicuShDHGmLgsSRhjjInLkoQxxpi4/j8PxjBgLVhq1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparaison du CA généré par chaque modèle\n",
    "dep = [dep8, dep9, dep10, dep11, dep12, dep13, dep14, CA_total, CA_total_nov]\n",
    "plt.plot(dep)\n",
    "plt.ylabel(\"Chiffre d'affaires généré\")\n",
    "plt.xlabel(\"Modèles\")\n",
    "plt.title(\"Comparaison du CA généré par chaque modèle\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les meilleurs modèles sont obtenus avec l'algorithme One Class SVM en utilisant les kernels polynomial et sigmoid.\n",
    "Pour ces deux kernels, les résultats en outlier detection et novelty detection sont équivalents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
